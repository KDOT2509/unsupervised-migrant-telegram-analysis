{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from bertopic import BERTopic\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# TODO  check babyplot for 3D visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(input_file):\n",
    "    with open(input_file) as file:\n",
    "        lines = file.readlines()\n",
    "        text_to_analyse_list = [line.rstrip() for line in lines]\n",
    "    return text_to_analyse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(\"../data/BERTopicInput.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTopic(verbose=True, language=\"multilingual\", nr_topics=30) # vectorizer_model=vectorizer_model)#, nr_topics=20)\n",
    "topics, probs = model.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "# setting path\n",
    "sys.path.append('../src/BERTopic/')\n",
    "from runBERTopic import BERTopicAnalysis\n",
    "\n",
    "nr_topics_list = [\"auto\"]\n",
    "min_topic_size_list = [10,25,50,100,200,400,800,1000,1500]\n",
    "hbscan_min_cluster_size_list = [25,50,100,200]\n",
    "\n",
    "\n",
    "for i in itertools.product(nr_topics_list,min_topic_size_list,hbscan_min_cluster_size_list):\n",
    "    if os.path.exists(f\"../models/BERTopic50Char{i[0].capitalize()}Classes{i[1]}MinTopicSize{i[2]}HbscanMinClusterSize/BERTopicmodel\"):\n",
    "        print('wuhu', i)\n",
    "        continue\n",
    "    BERTopic_Analysis = BERTopicAnalysis(input_file=\"../data/BERTopicInput50CharMin.csv\",\n",
    "                                         k_cluster=i[0],\n",
    "                                         min_topic_size=i[1],\n",
    "                                         hbscan_min_cluster_size=i[2]\n",
    "                                     )\n",
    "    print(i)    \n",
    "    BERTopic_Analysis.run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/BERTopicInput50CharMin.csv\") as file:\n",
    "    lines = file.readlines()\n",
    "    text_to_analyse_list = [line.rstrip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../models/BERTopic_50Char10Classes/pred_on_whole_data_translated_Sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "fp = open(\"test.txt\")\n",
    "data = fp.read()\n",
    "tokenizer.tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    if len(x) >= 500:\n",
    "        for i in tokenize.sent_tokenize(x):\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_counts = df[df.chat.isin(['https://t.me/zh_helps_ukraine', 'https://t.me/zh_helps_UArefugee',\n",
    "       'https://t.me/zurich_hb_help', 'https://t.me/zh_housing',\n",
    "       'https://t.me/Zurich_UA', 'https://t.me/zh_helps_UArefugees', 'https://t.me/Zh_helps_UA_mums', 'https://t.me/job_sw_ukrainians',\n",
    "       'https://t.me/zh_back_ukraine', 'https://t.me/zh_helps_logistics',])].value_counts(['cluster', 'week']).reset_index()\n",
    "df_value_counts.columns = ['cluster', 'week', 'count']\n",
    "mydict = {'no_class':-1,\n",
    "          'medical': 0, \n",
    "          'teaching': 1,\n",
    "          'banking': 2,\n",
    "          'transport_UKR_CH': 3,\n",
    "          'pets': 4,\n",
    "          'immigration': 5,\n",
    "          'transport_train_EU': 6,\n",
    "          'website_links': 7,\n",
    "          'volunteering': 8,\n",
    "          'transport_train_CH': 9}\n",
    "df_value_counts['cluster_names'] = df_value_counts['cluster'].apply(lambda x: list(mydict.keys())[list(mydict.values()).index(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actors = pd.DataFrame(columns=[\"cluster_name\", \"message_sender\", \"nr_post\"])\n",
    "for i in df.cluster_name.unique():\n",
    "    df[df['cluster_name']==i].value_counts('messageSender').iloc[:10]\n",
    "    df_actors_i = df[df['cluster_name']==i].value_counts('messageSender').iloc[:10].reset_index()\n",
    "    df_actors_i[\"cluster_name\"] = i\n",
    "    df_actors_i = df_actors_i[[\"cluster_name\", \"messageSender\", 0]]\n",
    "    df_actors_i.columns = [\"cluster_name\", \"message_sender\", \"nr_post\"]\n",
    "    df_actors = pd.concat([df_actors, df_actors_i], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"../models/BERTopic100CharMin2500CharMax_10ClassesRedo/df.csv\")\n",
    "df['uniqueIdentifier'] = df.apply(lambda x: x[\"chat\"] + \"_\" + str(x[\"messageID\"]), axis=1)\n",
    "df['uniqueIdentifierReply'] = df.apply(lambda x: x[\"chat\"] + \"_\" + str(x[\"messageReplyID\"])[:-2], axis=1)\n",
    "df = df[~df.chat.isin([\"https://t.me/campax_ukraine_help_switzerland\", \"https://t.me/helppetsfromukraine\"])] \n",
    "mydict = {'no_class':-1,\n",
    "          'medical': 0, \n",
    "          'legal_issues': 1,\n",
    "          'travel': 2,\n",
    "          'immigration': 3,\n",
    "          'childcare': 4,\n",
    "          'education': 5,\n",
    "          'veterinarian': 6,\n",
    "          'banking': 7,\n",
    "          'passport_information': 8,\n",
    "          'weblinks': 9}\n",
    "df['cluster_names'] = df['cluster'].apply(lambda x: list(mydict.keys())[list(mydict.values()).index(x)])\n",
    "df['week']=df['messageDatetime'].apply(lambda x: pd.to_datetime(x).isocalendar()[1])\n",
    "df_value_counts = df.groupby(['cluster','week']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# for i in df_value_counts.cluster.unique()[1:]:\n",
    "fig = px.line(df_value_counts[df_value_counts.cluster_names != \"no_class\"].sort_values(['week']), x=\"week\", y=\"count\", color='cluster_names', title='Cluster over time')\n",
    "fig.show()\n",
    "# fig.write_html(\"../models/BERTopic_50Char10Classes/AllGroups.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# for i in df_value_counts.cluster.unique()[1:]:\n",
    "fig = px.line(df_value_counts[df_value_counts.cluster != -1].sort_values(['week']), x=\"week\", y=\"count\", color='cluster_names', title='Cluster over time')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in df_value_counts.cluster.unique()[1:]:\n",
    "    plt.plot(df_value_counts[df_value_counts.cluster == i].sort_values(['week'])['week'], df_value_counts[df_value_counts.cluster == i].sort_values(['week'])['count'], linestyle = 'dotted', label=list(mydict.keys())[list(mydict.values()).index(i)])\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414616, 10)\n",
      "(62153, 10)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../models/BERTopic100CharMin2500CharMax_25/df.csv\")\n",
    "print(df.shape)\n",
    "df = df[df.cluster!=-1]\n",
    "print(df.shape)\n",
    "# df = df[df.messageTextEnglish.apply(type) == str]\n",
    "# print(df.shape)\n",
    "# df = df[df['messageTextEnglish'].notnull()]\n",
    "# print(df.shape)\n",
    "# df[df[\"messageText\"].str.len()<512]\n",
    "# df = df[df['messageTextEnglish'].str.len() <= 513]\n",
    "# df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.6600586771965027}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)\n",
    "sentiment_task(\"T'estimo!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::cumsum.out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universit√§t Z√ºrich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y113sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m text \u001b[39m=\u001b[39m preprocess(text)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y113sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m encoded_input \u001b[39m=\u001b[39m tokenizer(text, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y113sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mencoded_input)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y113sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m scores \u001b[39m=\u001b[39m output[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y113sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m scores \u001b[39m=\u001b[39m softmax(scores)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1218\u001b[0m, in \u001b[0;36mXLMRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1210\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1218\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[1;32m   1219\u001b[0m     input_ids,\n\u001b[1;32m   1220\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1221\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1222\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1223\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1224\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1225\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1226\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1227\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1228\u001b[0m )\n\u001b[1;32m   1229\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1230\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:841\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    839\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 841\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m    842\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    843\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    844\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m    845\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    846\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[1;32m    847\u001b[0m )\n\u001b[1;32m    848\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m    849\u001b[0m     embedding_output,\n\u001b[1;32m    850\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    858\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m    859\u001b[0m )\n\u001b[1;32m    860\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:102\u001b[0m, in \u001b[0;36mXLMRobertaEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m position_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m         \u001b[39m# Create the position ids from the input token ids. Any padded tokens remain padded.\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m         position_ids \u001b[39m=\u001b[39m create_position_ids_from_input_ids(input_ids, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, past_key_values_length)\n\u001b[1;32m    103\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m         position_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_position_ids_from_inputs_embeds(inputs_embeds)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1593\u001b[0m, in \u001b[0;36mcreate_position_ids_from_input_ids\u001b[0;34m(input_ids, padding_idx, past_key_values_length)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[39m# The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m mask \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mne(padding_idx)\u001b[39m.\u001b[39mint()\n\u001b[0;32m-> 1593\u001b[0m incremental_indices \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39;49mcumsum(mask, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mtype_as(mask) \u001b[39m+\u001b[39m past_key_values_length) \u001b[39m*\u001b[39m mask\n\u001b[1;32m   1594\u001b[0m \u001b[39mreturn\u001b[39;00m incremental_indices\u001b[39m.\u001b[39mlong() \u001b[39m+\u001b[39m padding_idx\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::cumsum.out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)#.to(\"mps\")\n",
    "model.to(\"mps\")\n",
    "text = \"Good night üòä\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt').to(\"mps\")\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "\n",
    "# text = \"Good night üòä\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "\n",
    "# Print labels and scores\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good night üòä'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")#.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "def analyse_sentiment(x):\n",
    "    if len(x)>512:\n",
    "        x_split_list = []\n",
    "        n = 400\n",
    "        for i in range(0, len(x), n):\n",
    "            x_split_list.append(x[i:i+n])\n",
    "        scores_split_list = []    \n",
    "        for x_split in x_split_list:\n",
    "            encoded_tweet = tokenizer(x_split, return_tensors='pt')#.to(\"mps\")\n",
    "            output = model(**encoded_tweet)\n",
    "            scores_split = output[0][0].detach().numpy()\n",
    "            scores_split = softmax(scores_split)\n",
    "            scores_split_list.append(scores_split)\n",
    "        return np.mean(np.array(scores_split_list), axis=0)\n",
    "        \n",
    "    else:\n",
    "        encoded_tweet = tokenizer(x, return_tensors='pt')#.to(\"mps\")\n",
    "        output = model(**encoded_tweet)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        return scores\n",
    "        \n",
    "def scores_to_sentiment(x):\n",
    "    max_value = max(x.tolist())\n",
    "    max_index = x.tolist().index(max_value)\n",
    "    return labels[max_index] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10218946"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[df.cluster!=-1].messageText.str.len())\n",
    "10218946\n",
    " 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"üëã–í—ñ—Ç–∞—î–º–æ –Ω–∞ –∫–∞–Ω–∞–ª—ñ –ö–û–†–ò–°–ù–û (HELPFUL) –®–≤–µ–π—Ü–∞—Ä—Å—å–∫–æ–≥–æ –ß–µ—Ä–≤–æ–Ω–æ–≥–æ –•—Ä–µ—Å—Ç–∞. –ú–∏ ‚Äî –≥—Ä—É–ø–∞ –≤–æ–ª–æ–Ω—Ç–µ—Ä—ñ–≤, —è–∫–∞ –¥–æ–ø–æ–º–æ–∂–µ –≤–∞–º –∑–Ω–∞–π—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –≤–∞—à—ñ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è. –ú–∏ –Ω–∞–º–∞–≥–∞—î–º–æ—Å—å –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏ –≤–ø—Ä–æ–¥–æ–≤–∂ 24 –≥–æ–¥–∏–Ω. –í—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è –Ω–∞–¥–∞—é—Ç—å—Å—è –∑ –ø–æ–Ω–µ–¥—ñ–ª–∫–∞ –ø–æ –ø‚Äô—è—Ç–Ω–∏—Ü—é. –ü–µ—Ä—à –Ω—ñ–∂ –ø–æ—Å—Ç–∞–≤–∏—Ç–∏ —Å–≤–æ—î –∑–∞–ø–∏—Ç–∞–Ω–Ω—è, –ø—Ä–æ—Å–∏–º–æ –≤–∞—Å —Å–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –≤–µ–±-—Å–∞–π—Ç –ö–û–†–ò–°–ù–û (HELPFUL): helpful.redcross.ch –ù–∞ —Ü—å–æ–º—É –∫–∞–Ω–∞–ª—ñ –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫—É, —Ä–æ—Å—ñ–π—Å—å–∫—É, –∞–Ω–≥–ª—ñ–π—Å—å–∫—É —Ç–∞ –¥–µ—Ä–∂–∞–≤–Ω—ñ –º–æ–≤–∏ –®–≤–µ–π—Ü–∞—Ä—ñ—ó. –ú–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏–º–µ–º–æ –∑–¥–µ–±—ñ–ª—å—à–æ–≥–æ –¥–µ—Ä–∂–∞–≤–Ω–∏–º–∏ –º–æ–≤–∞–º–∏ –®–≤–µ–π—Ü–∞—Ä—ñ—ó —Ç–∞ –ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏–º–µ–º–æ –ø–µ—Ä–µ–∫–ª–∞—Å—Ç–∏ –Ω–∞—à—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ. –î–ª—è —Ü—å–æ–≥–æ —Å–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ—Å—è —Ñ—É–Ω–∫—Ü—ñ—î—é ¬´–ø–µ—Ä–µ–∫–ª–∞–¥—É¬ª, —è–∫—É –ø—Ä–æ–ø–æ–Ω—É—î Telegram. –£–∫–∞–∑—ñ–≤–∫–∏ —Ç–∞ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –Ω–∞–≤–µ–¥–µ–Ω–æ –Ω–∏–∂—á–µ. ‚ö†Ô∏è–û—Å–∫—ñ–ª—å–∫–∏ —Ü–µ –ø—É–±–ª—ñ—á–Ω–∏–π –∫–∞–Ω–∞–ª, –≤–∞—à—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –±–∞—á–∏—Ç–∏–º—É—Ç—å –≤—Å—ñ –±–∞–∂–∞—é—á—ñ. –Ø–∫—â–æ —É –≤–∞—Å —î –∑–∞–ø–∏—Ç–∞–Ω–Ω—è, —â–æ –ø–µ—Ä–µ–¥–±–∞—á–∞—î —Ä–æ–∑–∫—Ä–∏—Ç—Ç—è –æ—Å–æ–±–∏—Å—Ç–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó, –ø—Ä–æ—Å–∏–º–æ –≤–∞—Å –¥–æ–¥–∞—Ç–∏ –≤ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –∑–Ω–∞—á–æ–∫ ‚úâÔ∏è. –¢–æ–¥—ñ –º–∏ –Ω–∞–¥—ñ—à–ª–µ–º–æ –≤–∞–º –ø—Ä–∏–≤–∞—Ç–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–æ–º—É —á–∞—Ç—ñ. üìç–í—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –¥–µ—è–∫—ñ –ø–∏—Ç–∞–Ω–Ω—è –±—É–ª–∏ –Ω–∞–¥–∞–Ω—ñ –≤ –ø—Ä–∏–≤–∞—Ç–Ω–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è—Ö. –ü—Ä–æ—Å–∏–º–æ –≤–∞—Å –ø–∏—Å–∞—Ç–∏ –ø—ñ–¥ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–º–∏ —Å–µ–∫—Ü—ñ—è–º–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º—É –∫–∞–Ω–∞–ª—ñ. ____ üëã–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –Ω–∞ –∫–∞–Ω–∞–ª HELPFUL –®–≤–µ–π—Ü–∞—Ä—Å–∫–æ–≥–æ –ö—Ä–∞—Å–Ω–æ–≥–æ –ö—Ä–µ—Å—Ç–∞. –ú—ã - –∫–æ–º–∞–Ω–¥–∞ –≤–æ–ª–æ–Ω—Ç–µ—Ä–æ–≤ –∏ –≥–æ—Ç–æ–≤—ã –ø–æ–º–æ—á—å –≤–∞–º –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã. –ú—ã —Å—Ç–∞—Ä–∞–µ–º—Å—è –¥–∞–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤ —Ç–µ—á–µ–Ω–∏–µ 24 —á–∞—Å–æ–≤. –ú—ã –±—É–¥–µ–º –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã —Å –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞ –ø–æ –ø—è—Ç–Ω–∏—Ü—É. –ü—Ä–µ–∂–¥–µ —á–µ–º –∑–∞–¥–∞—Ç—å —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å, –ø—Ä–æ—Å–∏–º –≤–∞—Å —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥–ª—è–Ω—É—Ç—å –Ω–∞ —Å–∞–π—Ç HELPFUL: helpful.redcross.ch. –ù–∞ —ç—Ç–æ–º –∫–∞–Ω–∞–ª–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π, —Ä—É—Å—Å–∫–∏–π, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∏–ª–∏ —à–≤–µ–π—Ü–∞—Ä—Å–∫–∏–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —è–∑—ã–∫–∏. –ú—ã –±—É–¥–µ–º –æ—Ç–≤–µ—á–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –Ω–∞ —è–∑—ã–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –≤ –®–≤–µ–π—Ü–∞—Ä–∏–∏, –∏ –ø—Ä–æ—Å–∏–º –≤–∞—Å –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –Ω–∞—à–∏ –æ—Ç–≤–µ—Ç—ã. –î–ª—è —ç—Ç–æ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –æ–ø—Ü–∏–µ–π \"\"–ø–µ—Ä–µ–≤–µ—Å—Ç–∏\"\", –∏–º–µ—é—â–µ–π—Å—è –≤ Telegram. –°–º–æ—Ç—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –Ω–∏–∂–µ. ‚ö†Ô∏è–ü–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–æ—Ç –∫–∞–Ω–∞–ª —è–≤–ª—è–µ—Ç—Å—è –ø—É–±–ª–∏—á–Ω—ã–º, –≤–∞—à–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ —Å–º–æ–∂–µ—Ç —É–≤–∏–¥–µ—Ç—å –∫–∞–∂–¥—ã–π. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å, –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞—é—â–∏–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–∞–∫–∏—Ö-—Ç–æ –ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ—Å–∏–º –≤–∞—Å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–Ω–∞—á–æ–∫ ‚úâÔ∏è –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –º—ã –æ—Ç–ø—Ä–∞–≤–∏–º –≤–∞–º –ª–∏—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —á–∞—Ç–µ. ___ üëã Welcome to the channel HELPFUL by the Swiss Red Cross. We are a team of volunteers and will help you find answers to your questions. We aim to respond within 24 hours. The questions will be answered from Monday to Friday. Before asking your question, we ask you to please first check the HELPFUL website: helpful.redcross.ch The languages used in this channel are Ukrainian, Russian, English or the Swiss national languages. We will mainly answer using the Swiss national languages and ask you to translate our answers. To do this please use the option ‚Äútranslate‚Äù provided by Telegram. See instructions in the comments below. ‚ö†Ô∏è As this channel is public, your comments will be seen by everyone. If you have a question that requires sharing some personal data, we ask you to send the icon ‚úâÔ∏è in the comment. We will then send you a private message in a secured chat. üìçSome answers are provided in private messages. We also please ask you to write under the appropriate sections in the main channel.\"\n",
    "x1 = \"Dear group members, We are pleased to announce that the **second part of the HELPFUL website** about staying in Switzerland is already online üéâ Please check out the published information on popular topics such as: work, education, finding accommodation and language learning here ‚û°Ô∏è https://helpful.redcross.ch/uk/perebuvannya We hope that you will find a lot of useful information for yourself and if you have any questions, we are ready to answer them. Have a nice day! Sincerely, HELPFUL Team\"\n",
    "x_split1 = analyse_sentiment(df.messageText[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_to_sentiment(x_split1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12221589, 0.8199387 , 0.05784534], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08510411, 0.78612053, 0.1287754 ], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(x_split), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 565])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_split[\"input_ids\"].shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['üëã–í—ñ—Ç–∞—î–º–æ –Ω–∞ –∫–∞–Ω–∞–ª—ñ –ö–û–†–ò–°–ù–û (HELPFUL) –®–≤–µ–π—Ü–∞—Ä—Å—å–∫–æ–≥–æ –ß–µ—Ä–≤–æ–Ω–æ–≥–æ –•—Ä–µ—Å—Ç–∞. –ú–∏ ‚Äî –≥—Ä—É–ø–∞ –≤–æ–ª–æ–Ω—Ç–µ—Ä—ñ–≤, —è–∫–∞ –¥–æ–ø–æ–º–æ–∂–µ –≤–∞–º –∑–Ω–∞–π—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –≤–∞—à—ñ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è. –ú–∏ –Ω–∞–º–∞–≥–∞—î–º–æ—Å—å –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏ –≤–ø—Ä–æ–¥–æ–≤–∂ 24 –≥–æ–¥–∏–Ω. –í—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è –Ω–∞–¥–∞—é—Ç—å—Å—è –∑ –ø–æ–Ω–µ–¥—ñ–ª–∫–∞ –ø–æ –ø‚Äô—è—Ç–Ω–∏—Ü—é. –ü–µ—Ä—à –Ω—ñ–∂ –ø–æ—Å—Ç–∞–≤–∏—Ç–∏ —Å–≤–æ—î –∑–∞–ø–∏—Ç–∞–Ω–Ω—è, –ø—Ä–æ—Å–∏–º–æ –≤–∞—Å —Å–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –≤–µ–±-—Å–∞–π—Ç –ö–û–†–ò–°–ù–û (HELPFUL): helpful.redcross.ch –ù–∞ —Ü—å–æ–º—É –∫–∞–Ω–∞–ª—ñ –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫—É, —Ä–æ—Å—ñ–π—Å—å–∫—É, –∞–Ω–≥–ª—ñ–π—Å—å–∫—É —Ç–∞ –¥–µ—Ä–∂–∞–≤–Ω—ñ –º–æ–≤–∏ –®–≤–µ–π—Ü–∞—Ä—ñ—ó. –ú–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏–º–µ–º–æ –∑–¥–µ–±—ñ–ª—å—à–æ–≥–æ –¥–µ—Ä–∂–∞–≤–Ω–∏–º–∏ –º–æ–≤–∞–º', '–∏ –®–≤–µ–π—Ü–∞—Ä—ñ—ó —Ç–∞ –ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏–º–µ–º–æ –ø–µ—Ä–µ–∫–ª–∞—Å—Ç–∏ –Ω–∞—à—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ. –î–ª—è —Ü—å–æ–≥–æ —Å–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ—Å—è —Ñ—É–Ω–∫—Ü—ñ—î—é ¬´–ø–µ—Ä–µ–∫–ª–∞–¥—É¬ª, —è–∫—É –ø—Ä–æ–ø–æ–Ω—É—î Telegram. –£–∫–∞–∑—ñ–≤–∫–∏ —Ç–∞ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –Ω–∞–≤–µ–¥–µ–Ω–æ –Ω–∏–∂—á–µ. ‚ö†Ô∏è–û—Å–∫—ñ–ª—å–∫–∏ —Ü–µ –ø—É–±–ª—ñ—á–Ω–∏–π –∫–∞–Ω–∞–ª, –≤–∞—à—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –±–∞—á–∏—Ç–∏–º—É—Ç—å –≤—Å—ñ –±–∞–∂–∞—é—á—ñ. –Ø–∫—â–æ —É –≤–∞—Å —î –∑–∞–ø–∏—Ç–∞–Ω–Ω—è, —â–æ –ø–µ—Ä–µ–¥–±–∞—á–∞—î —Ä–æ–∑–∫—Ä–∏—Ç—Ç—è –æ—Å–æ–±–∏—Å—Ç–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó, –ø—Ä–æ—Å–∏–º–æ –≤–∞—Å –¥–æ–¥–∞—Ç–∏ –≤ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –∑–Ω–∞—á–æ–∫ ‚úâÔ∏è. –¢–æ–¥—ñ –º–∏ –Ω–∞–¥—ñ—à–ª–µ–º–æ –≤–∞–º –ø—Ä–∏–≤–∞—Ç–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–æ–º—É —á–∞—Ç—ñ. üìç–í—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –¥–µ—è–∫—ñ –ø–∏—Ç–∞–Ω–Ω—è –±—É–ª–∏ –Ω–∞–¥–∞–Ω—ñ –≤ –ø—Ä–∏–≤–∞—Ç–Ω–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è—Ö. –ü—Ä–æ—Å–∏–º–æ –≤–∞—Å –ø–∏—Å–∞—Ç–∏ –ø—ñ–¥ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω', '–∏–º–∏ —Å–µ–∫—Ü—ñ—è–º–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º—É –∫–∞–Ω–∞–ª—ñ. ____ üëã–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –Ω–∞ –∫–∞–Ω–∞–ª HELPFUL –®–≤–µ–π—Ü–∞—Ä—Å–∫–æ–≥–æ –ö—Ä–∞—Å–Ω–æ–≥–æ –ö—Ä–µ—Å—Ç–∞. –ú—ã - –∫–æ–º–∞–Ω–¥–∞ –≤–æ–ª–æ–Ω—Ç–µ—Ä–æ–≤ –∏ –≥–æ—Ç–æ–≤—ã –ø–æ–º–æ—á—å –≤–∞–º –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã. –ú—ã —Å—Ç–∞—Ä–∞–µ–º—Å—è –¥–∞–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤ —Ç–µ—á–µ–Ω–∏–µ 24 —á–∞—Å–æ–≤. –ú—ã –±—É–¥–µ–º –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã —Å –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞ –ø–æ –ø—è—Ç–Ω–∏—Ü—É. –ü—Ä–µ–∂–¥–µ —á–µ–º –∑–∞–¥–∞—Ç—å —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å, –ø—Ä–æ—Å–∏–º –≤–∞—Å —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥–ª—è–Ω—É—Ç—å –Ω–∞ —Å–∞–π—Ç HELPFUL: helpful.redcross.ch. –ù–∞ —ç—Ç–æ–º –∫–∞–Ω–∞–ª–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π, —Ä—É—Å—Å–∫–∏–π, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∏–ª–∏ —à–≤–µ–π—Ü–∞—Ä—Å–∫–∏–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —è–∑—ã–∫–∏. –ú—ã –±—É–¥–µ–º –æ—Ç–≤–µ—á–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ', '–Ω–Ω–æ –Ω–∞ —è–∑—ã–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –≤ –®–≤–µ–π—Ü–∞—Ä–∏–∏, –∏ –ø—Ä–æ—Å–∏–º –≤–∞—Å –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –Ω–∞—à–∏ –æ—Ç–≤–µ—Ç—ã. –î–ª—è —ç—Ç–æ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –æ–ø—Ü–∏–µ–π –ø–µ—Ä–µ–≤–µ—Å—Ç–∏, –∏–º–µ—é—â–µ–π—Å—è –≤ Telegram. –°–º–æ—Ç—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –Ω–∏–∂–µ. ‚ö†Ô∏è–ü–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–æ—Ç –∫–∞–Ω–∞–ª —è–≤–ª—è–µ—Ç—Å—è –ø—É–±–ª–∏—á–Ω—ã–º, –≤–∞—à–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ —Å–º–æ–∂–µ—Ç —É–≤–∏–¥–µ—Ç—å –∫–∞–∂–¥—ã–π. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å, –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞—é—â–∏–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–∞–∫–∏—Ö-—Ç–æ –ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ—Å–∏–º –≤–∞—Å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–Ω–∞—á–æ–∫ ‚úâÔ∏è –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –º—ã –æ—Ç–ø—Ä–∞–≤–∏–º –≤–∞–º –ª–∏—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —á–∞—Ç–µ. ___ üëã Welcome to the channel HELPFUL by the Swiss Red Cr', 'oss. We are a team of volunteers and will help you find answers to your questions. We aim to respond within 24 hours. The questions will be answered from Monday to Friday. Before asking your question, we ask you to please first check the HELPFUL website: helpful.redcross.ch The languages used in this channel are Ukrainian, Russian, English or the Swiss national languages. We will mainly answer using the Swiss national languages and ask you to translate our answers. To do this please use the option ‚Äútranslat', 'e‚Äù provided by Telegram. See instructions in the comments below. ‚ö†Ô∏è As this channel is public, your comments will be seen by everyone. If you have a question that requires sharing some personal data, we ask you to send the icon ‚úâÔ∏è in the comment. We will then send you a private message in a secured chat. üìçSome answers are provided in private messages. We also please ask you to write under the appropriate sections in the main channel.']\n"
     ]
    }
   ],
   "source": [
    "x = \"üëã–í—ñ—Ç–∞—î–º–æ –Ω–∞ –∫–∞–Ω–∞–ª—ñ –ö–û–†–ò–°–ù–û (HELPFUL) –®–≤–µ–π—Ü–∞—Ä—Å—å–∫–æ–≥–æ –ß–µ—Ä–≤–æ–Ω–æ–≥–æ –•—Ä–µ—Å—Ç–∞. –ú–∏ ‚Äî –≥—Ä—É–ø–∞ –≤–æ–ª–æ–Ω—Ç–µ—Ä—ñ–≤, —è–∫–∞ –¥–æ–ø–æ–º–æ–∂–µ –≤–∞–º –∑–Ω–∞–π—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –≤–∞—à—ñ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è. –ú–∏ –Ω–∞–º–∞–≥–∞—î–º–æ—Å—å –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏ –≤–ø—Ä–æ–¥–æ–≤–∂ 24 –≥–æ–¥–∏–Ω. –í—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è –Ω–∞–¥–∞—é—Ç—å—Å—è –∑ –ø–æ–Ω–µ–¥—ñ–ª–∫–∞ –ø–æ –ø‚Äô—è—Ç–Ω–∏—Ü—é. –ü–µ—Ä—à –Ω—ñ–∂ –ø–æ—Å—Ç–∞–≤–∏—Ç–∏ —Å–≤–æ—î –∑–∞–ø–∏—Ç–∞–Ω–Ω—è, –ø—Ä–æ—Å–∏–º–æ –≤–∞—Å —Å–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –≤–µ–±-—Å–∞–π—Ç –ö–û–†–ò–°–ù–û (HELPFUL): helpful.redcross.ch –ù–∞ —Ü—å–æ–º—É –∫–∞–Ω–∞–ª—ñ –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫—É, —Ä–æ—Å—ñ–π—Å—å–∫—É, –∞–Ω–≥–ª—ñ–π—Å—å–∫—É —Ç–∞ –¥–µ—Ä–∂–∞–≤–Ω—ñ –º–æ–≤–∏ –®–≤–µ–π—Ü–∞—Ä—ñ—ó. –ú–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏–º–µ–º–æ –∑–¥–µ–±—ñ–ª—å—à–æ–≥–æ –¥–µ—Ä–∂–∞–≤–Ω–∏–º–∏ –º–æ–≤–∞–º–∏ –®–≤–µ–π—Ü–∞—Ä—ñ—ó —Ç–∞ –ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏–º–µ–º–æ –ø–µ—Ä–µ–∫–ª–∞—Å—Ç–∏ –Ω–∞—à—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ. –î–ª—è —Ü—å–æ–≥–æ —Å–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ—Å—è —Ñ—É–Ω–∫—Ü—ñ—î—é ¬´–ø–µ—Ä–µ–∫–ª–∞–¥—É¬ª, —è–∫—É –ø—Ä–æ–ø–æ–Ω—É—î Telegram. –£–∫–∞–∑—ñ–≤–∫–∏ —Ç–∞ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –Ω–∞–≤–µ–¥–µ–Ω–æ –Ω–∏–∂—á–µ. ‚ö†Ô∏è–û—Å–∫—ñ–ª—å–∫–∏ —Ü–µ –ø—É–±–ª—ñ—á–Ω–∏–π –∫–∞–Ω–∞–ª, –≤–∞—à—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –±–∞—á–∏—Ç–∏–º—É—Ç—å –≤—Å—ñ –±–∞–∂–∞—é—á—ñ. –Ø–∫—â–æ —É –≤–∞—Å —î –∑–∞–ø–∏—Ç–∞–Ω–Ω—è, —â–æ –ø–µ—Ä–µ–¥–±–∞—á–∞—î —Ä–æ–∑–∫—Ä–∏—Ç—Ç—è –æ—Å–æ–±–∏—Å—Ç–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó, –ø—Ä–æ—Å–∏–º–æ –≤–∞—Å –¥–æ–¥–∞—Ç–∏ –≤ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –∑–Ω–∞—á–æ–∫ ‚úâÔ∏è. –¢–æ–¥—ñ –º–∏ –Ω–∞–¥—ñ—à–ª–µ–º–æ –≤–∞–º –ø—Ä–∏–≤–∞—Ç–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–æ–º—É —á–∞—Ç—ñ. üìç–í—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –¥–µ—è–∫—ñ –ø–∏—Ç–∞–Ω–Ω—è –±—É–ª–∏ –Ω–∞–¥–∞–Ω—ñ –≤ –ø—Ä–∏–≤–∞—Ç–Ω–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è—Ö. –ü—Ä–æ—Å–∏–º–æ –≤–∞—Å –ø–∏—Å–∞—Ç–∏ –ø—ñ–¥ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–º–∏ —Å–µ–∫—Ü—ñ—è–º–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º—É –∫–∞–Ω–∞–ª—ñ. ____ üëã–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –Ω–∞ –∫–∞–Ω–∞–ª HELPFUL –®–≤–µ–π—Ü–∞—Ä—Å–∫–æ–≥–æ –ö—Ä–∞—Å–Ω–æ–≥–æ –ö—Ä–µ—Å—Ç–∞. –ú—ã - –∫–æ–º–∞–Ω–¥–∞ –≤–æ–ª–æ–Ω—Ç–µ—Ä–æ–≤ –∏ –≥–æ—Ç–æ–≤—ã –ø–æ–º–æ—á—å –≤–∞–º –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã. –ú—ã —Å—Ç–∞—Ä–∞–µ–º—Å—è –¥–∞–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤ —Ç–µ—á–µ–Ω–∏–µ 24 —á–∞—Å–æ–≤. –ú—ã –±—É–¥–µ–º –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã —Å –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞ –ø–æ –ø—è—Ç–Ω–∏—Ü—É. –ü—Ä–µ–∂–¥–µ —á–µ–º –∑–∞–¥–∞—Ç—å —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å, –ø—Ä–æ—Å–∏–º –≤–∞—Å —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥–ª—è–Ω—É—Ç—å –Ω–∞ —Å–∞–π—Ç HELPFUL: helpful.redcross.ch. –ù–∞ —ç—Ç–æ–º –∫–∞–Ω–∞–ª–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π, —Ä—É—Å—Å–∫–∏–π, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∏–ª–∏ —à–≤–µ–π—Ü–∞—Ä—Å–∫–∏–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —è–∑—ã–∫–∏. –ú—ã –±—É–¥–µ–º –æ—Ç–≤–µ—á–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –Ω–∞ —è–∑—ã–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –≤ –®–≤–µ–π—Ü–∞—Ä–∏–∏, –∏ –ø—Ä–æ—Å–∏–º –≤–∞—Å –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –Ω–∞—à–∏ –æ—Ç–≤–µ—Ç—ã. –î–ª—è —ç—Ç–æ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –æ–ø—Ü–∏–µ–π \"\"–ø–µ—Ä–µ–≤–µ—Å—Ç–∏\"\", –∏–º–µ—é—â–µ–π—Å—è –≤ Telegram. –°–º–æ—Ç—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –Ω–∏–∂–µ. ‚ö†Ô∏è–ü–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–æ—Ç –∫–∞–Ω–∞–ª —è–≤–ª—è–µ—Ç—Å—è –ø—É–±–ª–∏—á–Ω—ã–º, –≤–∞—à–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ —Å–º–æ–∂–µ—Ç —É–≤–∏–¥–µ—Ç—å –∫–∞–∂–¥—ã–π. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å, –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞—é—â–∏–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–∞–∫–∏—Ö-—Ç–æ –ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ—Å–∏–º –≤–∞—Å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–Ω–∞—á–æ–∫ ‚úâÔ∏è –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –º—ã –æ—Ç–ø—Ä–∞–≤–∏–º –≤–∞–º –ª–∏—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —á–∞—Ç–µ. ___ üëã Welcome to the channel HELPFUL by the Swiss Red Cross. We are a team of volunteers and will help you find answers to your questions. We aim to respond within 24 hours. The questions will be answered from Monday to Friday. Before asking your question, we ask you to please first check the HELPFUL website: helpful.redcross.ch The languages used in this channel are Ukrainian, Russian, English or the Swiss national languages. We will mainly answer using the Swiss national languages and ask you to translate our answers. To do this please use the option ‚Äútranslate‚Äù provided by Telegram. See instructions in the comments below. ‚ö†Ô∏è As this channel is public, your comments will be seen by everyone. If you have a question that requires sharing some personal data, we ask you to send the icon ‚úâÔ∏è in the comment. We will then send you a private message in a secured chat. üìçSome answers are provided in private messages. We also please ask you to write under the appropriate sections in the main channel.\"\n",
    "\n",
    "my_list = []\n",
    "\n",
    "n = 512\n",
    "\n",
    "for i in range(0, len(x), n):\n",
    "    my_list.append(x[i:i+n])\n",
    "\n",
    "print(my_list)  # üëâÔ∏è ['ab', 'cd', 'ef', 'gh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/BERTopic100CharMin2500CharMax_20/df'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'models/BERTopic100CharMin2500CharMax_20/df.csv'.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"üëã–í—ñ—Ç–∞—î–º–æ –Ω–∞ –∫–∞–Ω–∞–ª—ñ –ö–û–†–ò–°–ù–û (HELPFUL) –®–≤–µ–π—Ü–∞—Ä—Å—å–∫–æ–≥–æ –ß–µ—Ä–≤–æ–Ω–æ–≥–æ –•—Ä–µ—Å—Ç–∞. –ú–∏ ‚Äî –≥—Ä—É–ø–∞ –≤–æ–ª–æ–Ω—Ç–µ—Ä—ñ–≤, —è–∫–∞ –¥–æ–ø–æ–º–æ–∂–µ –≤–∞–º –∑–Ω–∞–π—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –≤–∞—à—ñ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è. –ú–∏ –Ω–∞–º–∞–≥–∞—î–º–æ—Å—å –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏ –≤–ø—Ä–æ–¥–æ–≤–∂ 24 –≥–æ–¥–∏–Ω. –í—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è –Ω–∞–¥–∞—é—Ç—å—Å—è –∑ –ø–æ–Ω–µ–¥—ñ–ª–∫–∞ –ø–æ –ø‚Äô—è—Ç–Ω–∏—Ü—é. –ü–µ—Ä—à –Ω—ñ–∂ –ø–æ—Å—Ç–∞–≤–∏—Ç–∏ —Å–≤–æ—î –∑–∞–ø–∏—Ç–∞–Ω–Ω—è, –ø—Ä–æ—Å–∏–º–æ –≤–∞—Å —Å–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –≤–µ–±-—Å–∞–π—Ç –ö–û–†–ò–°–ù–û (HELPFUL): helpful.redcross.ch –ù–∞ —Ü—å–æ–º—É –∫–∞–Ω–∞–ª—ñ –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫—É, —Ä–æ—Å—ñ–π—Å—å–∫—É, –∞–Ω–≥–ª—ñ–π—Å—å–∫—É —Ç–∞ –¥–µ—Ä–∂–∞–≤–Ω—ñ –º–æ–≤–∏ –®–≤–µ–π—Ü–∞—Ä—ñ—ó. –ú–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏–º–µ–º–æ –∑–¥–µ–±—ñ–ª—å—à–æ–≥–æ –¥–µ—Ä–∂–∞–≤–Ω–∏–º–∏ –º–æ–≤–∞–º–∏ –®–≤–µ–π—Ü–∞—Ä—ñ—ó —Ç–∞ –ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏–º–µ–º–æ –ø–µ—Ä–µ–∫–ª–∞—Å—Ç–∏ –Ω–∞—à—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ. –î–ª—è —Ü—å–æ–≥–æ —Å–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ—Å—è —Ñ—É–Ω–∫—Ü—ñ—î—é ¬´–ø–µ—Ä–µ–∫–ª–∞–¥—É¬ª, —è–∫—É –ø—Ä–æ–ø–æ–Ω—É—î Telegram. –£–∫–∞–∑—ñ–≤–∫–∏ —Ç–∞ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –Ω–∞–≤–µ–¥–µ–Ω–æ –Ω–∏–∂—á–µ. ‚ö†Ô∏è–û—Å–∫—ñ–ª—å–∫–∏ —Ü–µ –ø—É–±–ª—ñ—á–Ω–∏–π –∫–∞–Ω–∞–ª, –≤–∞—à—ñ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –±–∞—á–∏—Ç–∏–º—É—Ç—å –≤—Å—ñ –±–∞–∂–∞—é—á—ñ. –Ø–∫—â–æ —É –≤–∞—Å —î –∑–∞–ø–∏—Ç–∞–Ω–Ω—è, —â–æ –ø–µ—Ä–µ–¥–±–∞—á–∞—î —Ä–æ–∑–∫—Ä–∏—Ç—Ç—è –æ—Å–æ–±–∏—Å—Ç–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó, –ø—Ä–æ—Å–∏–º–æ –≤–∞—Å –¥–æ–¥–∞—Ç–∏ –≤ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ –∑–Ω–∞—á–æ–∫ ‚úâÔ∏è. –¢–æ–¥—ñ –º–∏ –Ω–∞–¥—ñ—à–ª–µ–º–æ –≤–∞–º –ø—Ä–∏–≤–∞—Ç–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–æ–º—É —á–∞—Ç—ñ. üìç–í—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –¥–µ—è–∫—ñ –ø–∏—Ç–∞–Ω–Ω—è –±—É–ª–∏ –Ω–∞–¥–∞–Ω—ñ –≤ –ø—Ä–∏–≤–∞—Ç–Ω–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è—Ö. –ü—Ä–æ—Å–∏–º–æ –≤–∞—Å –ø–∏—Å–∞—Ç–∏ –ø—ñ–¥ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–º–∏ —Å–µ–∫—Ü—ñ—è–º–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º—É –∫–∞–Ω–∞–ª—ñ. ____ üëã–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –Ω–∞ –∫–∞–Ω–∞–ª HELPFUL –®–≤–µ–π—Ü–∞—Ä—Å–∫–æ–≥–æ –ö—Ä–∞—Å–Ω–æ–≥–æ –ö—Ä–µ—Å—Ç–∞. –ú—ã - –∫–æ–º–∞–Ω–¥–∞ –≤–æ–ª–æ–Ω—Ç–µ—Ä–æ–≤ –∏ –≥–æ—Ç–æ–≤—ã –ø–æ–º–æ—á—å –≤–∞–º –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã. –ú—ã —Å—Ç–∞—Ä–∞–µ–º—Å—è –¥–∞–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤ —Ç–µ—á–µ–Ω–∏–µ 24 —á–∞—Å–æ–≤. –ú—ã –±—É–¥–µ–º –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã —Å –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞ –ø–æ –ø—è—Ç–Ω–∏—Ü—É. –ü—Ä–µ–∂–¥–µ —á–µ–º –∑–∞–¥–∞—Ç—å —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å, –ø—Ä–æ—Å–∏–º –≤–∞—Å —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥–ª—è–Ω—É—Ç—å –Ω–∞ —Å–∞–π—Ç HELPFUL: helpful.redcross.ch. –ù–∞ —ç—Ç–æ–º –∫–∞–Ω–∞–ª–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π, —Ä—É—Å—Å–∫–∏–π, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∏–ª–∏ —à–≤–µ–π—Ü–∞—Ä—Å–∫–∏–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —è–∑—ã–∫–∏. –ú—ã –±—É–¥–µ–º –æ—Ç–≤–µ—á–∞—Ç—å –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –Ω–∞ —è–∑—ã–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –≤ –®–≤–µ–π—Ü–∞—Ä–∏–∏, –∏ –ø—Ä–æ—Å–∏–º –≤–∞—Å –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –Ω–∞—à–∏ –æ—Ç–≤–µ—Ç—ã. –î–ª—è —ç—Ç–æ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –æ–ø—Ü–∏–µ–π \"\"–ø–µ—Ä–µ–≤–µ—Å—Ç–∏\"\", –∏–º–µ—é—â–µ–π—Å—è –≤ Telegram. –°–º–æ—Ç—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –Ω–∏–∂–µ. ‚ö†Ô∏è–ü–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–æ—Ç –∫–∞–Ω–∞–ª —è–≤–ª—è–µ—Ç—Å—è –ø—É–±–ª–∏—á–Ω—ã–º, –≤–∞—à–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ —Å–º–æ–∂–µ—Ç —É–≤–∏–¥–µ—Ç—å –∫–∞–∂–¥—ã–π. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å, –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞—é—â–∏–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–∞–∫–∏—Ö-—Ç–æ –ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ—Å–∏–º –≤–∞—Å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–Ω–∞—á–æ–∫ ‚úâÔ∏è –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –º—ã –æ—Ç–ø—Ä–∞–≤–∏–º –≤–∞–º –ª–∏—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —á–∞—Ç–µ. ___ üëã Welcome to the channel HELPFUL by the Swiss Red Cross. We are a team of volunteers and will help you find answers to your questions. We aim to respond within 24 hours. The questions will be answered from Monday to Friday. Before asking your question, we ask you to please first check the HELPFUL website: helpful.redcross.ch The languages used in this channel are Ukrainian, Russian, English or the Swiss national languages. We will mainly answer using the Swiss national languages and ask you to translate our answers. To do this please use the option ‚Äútranslate‚Äù provided by Telegram. See instructions in the comments below. ‚ö†Ô∏è As this channel is public, your comments will be seen by everyone. If you have a question that requires sharing some personal data, we ask you to send the icon ‚úâÔ∏è in the comment. We will then send you a private message in a secured chat. üìçSome answers are provided in private messages. We also please ask you to write under the appropriate sections in the main channel.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 414616/414616 [00:00<00:00, 1092111.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df['sentiment'] = df['messageText'].progress_apply(lambda x: analyse_sentiment(x))\n",
    "df['sentiment_name'] = df['sentiment'].progress_apply(lambda x: scores_to_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test= df_test.sort_values(\"sentiment_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "sentiment_name=Negative<br>cluster_name=%{x}<br>percentage=%{y}<extra></extra>",
         "legendgroup": "Negative",
         "marker": {
          "color": "red",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Negative",
         "offsetgroup": "Negative",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "transport_UKR_CH",
          "volunteering",
          "transport_train_EU",
          "transport_train_CH",
          "immigration",
          "medical",
          "teaching",
          "banking",
          "pets",
          "website_links"
         ],
         "xaxis": "x",
         "y": [
          0.032595573440643864,
          0.07445805843543826,
          0.0882816605359958,
          0.10039481105470953,
          0.15559655596555966,
          0.22366602156483273,
          0.09029411764705883,
          0.10580847723704867,
          0.18043087971274685,
          0.05168986083499006
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "sentiment_name=Neutral<br>cluster_name=%{x}<br>percentage=%{y}<extra></extra>",
         "legendgroup": "Neutral",
         "marker": {
          "color": "blue",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Neutral",
         "offsetgroup": "Neutral",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "medical",
          "banking",
          "transport_train_CH",
          "transport_train_EU",
          "pets",
          "teaching",
          "volunteering",
          "transport_UKR_CH",
          "immigration",
          "website_links"
         ],
         "xaxis": "x",
         "y": [
          0.7005805916505391,
          0.8091051805337519,
          0.7794698251551043,
          0.7714135575407252,
          0.6723518850987432,
          0.5882352941176471,
          0.7290292177191329,
          0.7352112676056338,
          0.7718327183271833,
          0.856858846918489
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "sentiment_name=Positive<br>cluster_name=%{x}<br>percentage=%{y}<extra></extra>",
         "legendgroup": "Positive",
         "marker": {
          "color": "green",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Positive",
         "offsetgroup": "Positive",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "teaching",
          "immigration",
          "website_links",
          "transport_train_EU",
          "banking",
          "pets",
          "medical",
          "transport_UKR_CH",
          "transport_train_CH",
          "volunteering"
         ],
         "xaxis": "x",
         "y": [
          0.3214705882352941,
          0.07257072570725707,
          0.09145129224652088,
          0.14030478192327903,
          0.08508634222919938,
          0.14721723518850988,
          0.07575338678462815,
          0.23219315895372233,
          0.12013536379018612,
          0.19651272384542884
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "sentiment_name"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Sentiment within cluster"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "cluster_name"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "percentage"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "long_df = px.data.medals_long()\n",
    "\n",
    "fig = px.bar(df_test, x=\"cluster_name\", y='percentage', color=\"sentiment_name\", title=\"Sentiment within cluster\", color_discrete_map={'Negative':'red', 'Neutral':'blue', 'Positive':'green'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "long_df = px.data.medals_long()\n",
    "\n",
    "fig = px.bar(df_test, x=\"cluster_name\", y=\"percentage\", color=\"sentiment_name\", title=\"Sentiment within cluster\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.cluster.unique():\n",
    "    print(i)\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(df[df.cluster==i].value_counts('sentiment_name').values, labels=df[df.cluster==i].value_counts('sentiment_name').index, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    title = list(mydict.keys())[list(mydict.values()).index(i)]\n",
    "    fig1.suptitle(title, fontsize=12)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "long_df = px.data.medals_long()\n",
    "\n",
    "fig = px.bar(long_df, x=\"nation\", y=\"count\", color=\"medal\", title=\"Long-Form Input\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/kiliansprenkamp/Desktop/OneDrive - Universit√§t Z√ºrich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/models/BERTopic_50Char10Classes/pred_on_whole_data_translated_sentiment_network.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.messageText.str.len().nlargest(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear members of the group, We are glad to announce that **the second part of the HELPFUL website** about staying in Switzerland is already online  Please view the published information on popular topics such as: work, education, housing search and language study here  https://helpful.redcross.ch/uk/perebuvannya Hope you find yourself useful!'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformer for slavic to english\n",
    "\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "import torch\n",
    "\n",
    "# src = \"uk\"  # source language\n",
    "# trg = \"en\"  # target language\n",
    "\n",
    "model_name = f\"Helsinki-NLP/opus-mt-tc-big-zle-en\"\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# tokenizer.to(\"mps\")\n",
    "\n",
    "# model.to(torch.device(\"mps\"))\n",
    "sample_text =  df.messageText[0]\n",
    "batch = tokenizer([sample_text], return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(**batch)\n",
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/62153 [05:46<186:43:27, 10.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universit√§t Z√ºrich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y134sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mmessageTextEnglish\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mmessageText\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mprogress_apply(\u001b[39mlambda\u001b[39;49;00m x: tokenizer\u001b[39m.\u001b[39;49mbatch_decode(model\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtokenizer([x], return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)), skip_special_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/tqdm/std.py:814\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    815\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    816\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/tqdm/std.py:809\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    804\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    805\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    807\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 809\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universit√§t Z√ºrich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 45\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y134sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mmessageTextEnglish\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mmessageText\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: tokenizer\u001b[39m.\u001b[39mbatch_decode(model\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtokenizer([x], return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)), skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:1577\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1574\u001b[0m         input_ids, expand_size\u001b[39m=\u001b[39mnum_beams, is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs\n\u001b[1;32m   1575\u001b[0m     )\n\u001b[1;32m   1576\u001b[0m     \u001b[39m# 12. run beam search\u001b[39;00m\n\u001b[0;32m-> 1577\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[1;32m   1578\u001b[0m         input_ids,\n\u001b[1;32m   1579\u001b[0m         beam_scorer,\n\u001b[1;32m   1580\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1581\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1582\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1583\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1584\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   1585\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1586\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1587\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1588\u001b[0m     )\n\u001b[1;32m   1590\u001b[0m \u001b[39melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   1591\u001b[0m     \u001b[39m# 10. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1593\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m   1594\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         renormalize_logits\u001b[39m=\u001b[39mrenormalize_logits,\n\u001b[1;32m   1599\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:2747\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2743\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   2745\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 2747\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2748\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2749\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2750\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2751\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2752\u001b[0m )\n\u001b[1;32m   2754\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2755\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:1457\u001b[0m, in \u001b[0;36mMarianMTModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1437\u001b[0m             labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1438\u001b[0m         )\n\u001b[1;32m   1440\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\n\u001b[1;32m   1441\u001b[0m     input_ids,\n\u001b[1;32m   1442\u001b[0m     attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1456\u001b[0m )\n\u001b[0;32m-> 1457\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlm_head(outputs[\u001b[39m0\u001b[39;49m]) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_logits_bias\n\u001b[1;32m   1459\u001b[0m masked_lm_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1460\u001b[0m \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['messageTextEnglish'] = df['messageText'].progress_apply(lambda x: tokenizer.batch_decode(model.generate(**tokenizer([x], return_tensors=\"pt\")), skip_special_tokens=True)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::remainder.Tensor_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universit√§t Z√ºrich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y131sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pipe \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHelsinki-NLP/opus-mt-tc-big-zle-en\u001b[39m\u001b[39m\"\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y131sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(pipe(\u001b[39m\"\u001b[39;49m\u001b[39m–°–∫—ñ–ª—å–∫–∏ –º–µ–Ω—ñ —Å–ª—ñ–¥ –∫—É–ø–∏—Ç–∏ –ø–∏–≤–∞?\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:351\u001b[0m, in \u001b[0;36mTranslationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    322\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39m    Translate the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39m          token ids of the translation.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:150\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    152\u001b[0m         \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m)\n\u001b[1;32m    153\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(el, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m args[\u001b[39m0\u001b[39m])\n\u001b[1;32m    154\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result)\n\u001b[1;32m    155\u001b[0m     ):\n\u001b[1;32m    156\u001b[0m         \u001b[39mreturn\u001b[39;00m [res[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:1074\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1073\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1074\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:1081\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1080\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1081\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1082\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1083\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:990\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m    989\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 990\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m    991\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    992\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:172\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generate_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_length)\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m], generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 172\u001b[0m output_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[1;32m    173\u001b[0m out_b \u001b[39m=\u001b[39m output_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:1577\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1574\u001b[0m         input_ids, expand_size\u001b[39m=\u001b[39mnum_beams, is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs\n\u001b[1;32m   1575\u001b[0m     )\n\u001b[1;32m   1576\u001b[0m     \u001b[39m# 12. run beam search\u001b[39;00m\n\u001b[0;32m-> 1577\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[1;32m   1578\u001b[0m         input_ids,\n\u001b[1;32m   1579\u001b[0m         beam_scorer,\n\u001b[1;32m   1580\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1581\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1582\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1583\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1584\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   1585\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1586\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1587\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1588\u001b[0m     )\n\u001b[1;32m   1590\u001b[0m \u001b[39melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   1591\u001b[0m     \u001b[39m# 10. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1593\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m   1594\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         renormalize_logits\u001b[39m=\u001b[39mrenormalize_logits,\n\u001b[1;32m   1599\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:2797\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2792\u001b[0m next_token_scores, next_tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(\n\u001b[1;32m   2793\u001b[0m     next_token_scores, \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m num_beams, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, largest\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39msorted\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2794\u001b[0m )\n\u001b[1;32m   2796\u001b[0m next_indices \u001b[39m=\u001b[39m torch_int_div(next_tokens, vocab_size)\n\u001b[0;32m-> 2797\u001b[0m next_tokens \u001b[39m=\u001b[39m next_tokens \u001b[39m%\u001b[39;49m vocab_size\n\u001b[1;32m   2799\u001b[0m \u001b[39m# stateless\u001b[39;00m\n\u001b[1;32m   2800\u001b[0m beam_outputs \u001b[39m=\u001b[39m beam_scorer\u001b[39m.\u001b[39mprocess(\n\u001b[1;32m   2801\u001b[0m     input_ids,\n\u001b[1;32m   2802\u001b[0m     next_token_scores,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2807\u001b[0m     beam_indices\u001b[39m=\u001b[39mbeam_indices,\n\u001b[1;32m   2808\u001b[0m )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::remainder.Tensor_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-tc-big-zle-en\", device=\"mps\")\n",
    "print(pipe(\"–°–∫—ñ–ª—å–∫–∏ –º–µ–Ω—ñ —Å–ª—ñ–¥ –∫—É–ø–∏—Ç–∏ –ø–∏–≤–∞?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/414616 [00:25<196:40:47,  1.71s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universit√§t Z√ºrich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y132sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mmessageTextEnglish\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mmessageText\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mprogress_apply(\u001b[39mlambda\u001b[39;49;00m x: pipe(x, max_length\u001b[39m=\u001b[39;49m\u001b[39m2500\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/tqdm/std.py:814\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    815\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    816\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/tqdm/std.py:809\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    804\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    805\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    807\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 809\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universit√§t Z√ºrich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 45\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y132sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mmessageTextEnglish\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mmessageText\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: pipe(x, max_length\u001b[39m=\u001b[39;49m\u001b[39m2500\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:351\u001b[0m, in \u001b[0;36mTranslationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    322\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39m    Translate the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39m          token ids of the translation.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:150\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    152\u001b[0m         \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m)\n\u001b[1;32m    153\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(el, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m args[\u001b[39m0\u001b[39m])\n\u001b[1;32m    154\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result)\n\u001b[1;32m    155\u001b[0m     ):\n\u001b[1;32m    156\u001b[0m         \u001b[39mreturn\u001b[39;00m [res[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:1074\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1073\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1074\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:1081\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1080\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1081\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1082\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1083\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:990\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m    989\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 990\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m    991\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    992\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:172\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generate_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_length)\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m], generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 172\u001b[0m output_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[1;32m    173\u001b[0m out_b \u001b[39m=\u001b[39m output_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:1577\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1574\u001b[0m         input_ids, expand_size\u001b[39m=\u001b[39mnum_beams, is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs\n\u001b[1;32m   1575\u001b[0m     )\n\u001b[1;32m   1576\u001b[0m     \u001b[39m# 12. run beam search\u001b[39;00m\n\u001b[0;32m-> 1577\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[1;32m   1578\u001b[0m         input_ids,\n\u001b[1;32m   1579\u001b[0m         beam_scorer,\n\u001b[1;32m   1580\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1581\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1582\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1583\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1584\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   1585\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1586\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1587\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1588\u001b[0m     )\n\u001b[1;32m   1590\u001b[0m \u001b[39melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   1591\u001b[0m     \u001b[39m# 10. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1593\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m   1594\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         renormalize_logits\u001b[39m=\u001b[39mrenormalize_logits,\n\u001b[1;32m   1599\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:2747\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2743\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   2745\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 2747\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2748\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2749\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2750\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2751\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2752\u001b[0m )\n\u001b[1;32m   2754\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2755\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:1440\u001b[0m, in \u001b[0;36mMarianMTModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1435\u001b[0m     \u001b[39mif\u001b[39;00m decoder_input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decoder_inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1436\u001b[0m         decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1437\u001b[0m             labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1438\u001b[0m         )\n\u001b[0;32m-> 1440\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1441\u001b[0m     input_ids,\n\u001b[1;32m   1442\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1443\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1444\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   1445\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1446\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1447\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1448\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1449\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1450\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1451\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1452\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1453\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1454\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1455\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1456\u001b[0m )\n\u001b[1;32m   1457\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(outputs[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_logits_bias\n\u001b[1;32m   1459\u001b[0m masked_lm_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:1240\u001b[0m, in \u001b[0;36mMarianModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1233\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1234\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1235\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1237\u001b[0m     )\n\u001b[1;32m   1239\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1240\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1241\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1242\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1243\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_outputs[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m   1244\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1245\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1246\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1247\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1248\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1249\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1250\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1251\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1252\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1253\u001b[0m )\n\u001b[1;32m   1255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1256\u001b[0m     \u001b[39mreturn\u001b[39;00m decoder_outputs \u001b[39m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:1042\u001b[0m, in \u001b[0;36mMarianDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m   1031\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m   1032\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1039\u001b[0m     )\n\u001b[1;32m   1040\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1042\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m   1043\u001b[0m         hidden_states,\n\u001b[1;32m   1044\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1045\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1046\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1047\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1048\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49m(\n\u001b[1;32m   1049\u001b[0m             cross_attn_head_mask[idx] \u001b[39mif\u001b[39;49;00m cross_attn_head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   1050\u001b[0m         ),\n\u001b[1;32m   1051\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1052\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1053\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1054\u001b[0m     )\n\u001b[1;32m   1055\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1057\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:424\u001b[0m, in \u001b[0;36mMarianDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    422\u001b[0m self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    425\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    426\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    427\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    428\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    429\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    430\u001b[0m )\n\u001b[1;32m    431\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m    432\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:208\u001b[0m, in \u001b[0;36mMarianAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39melif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39m# reuse k, v, self_attention\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     key_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj(hidden_states), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, bsz)\n\u001b[0;32m--> 208\u001b[0m     value_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj(hidden_states), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, bsz)\n\u001b[1;32m    209\u001b[0m     key_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([past_key_value[\u001b[39m0\u001b[39m], key_states], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    210\u001b[0m     value_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([past_key_value[\u001b[39m1\u001b[39m], value_states], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df[\"messageTextEnglish\"] = df[\"messageText\"].progress_apply(lambda x: pipe(x, max_length=2500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# potential publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../models//BERTopic100CharMin2500CharMax_10ClassesNewestData/df.csv\")\n",
    "df['uniqueIdentifier'] = df.apply(lambda x: x[\"chat\"] + \"_\" + str(x[\"messageID\"]), axis=1)\n",
    "df['uniqueIdentifierReply'] = df.apply(lambda x: x[\"chat\"] + \"_\" + str(x[\"messageReplyID\"])[:-2], axis=1)\n",
    "# df = df[~df.chat.isin([\"https://t.me/campax_ukraine_help_switzerland\", \"https://t.me/helppetsfromukraine\"])] \n",
    "class_name_dict = {'no_class':-1,\n",
    "          'Medical': 0, \n",
    "          'Complaints': 1,\n",
    "          'Asylum/Volunteering': 2,\n",
    "          'Banking': 3,\n",
    "          'Train Travel': 4,\n",
    "          'S Status': 5,\n",
    "          'Accomodation': 6,\n",
    "          'Veterinarian': 7,\n",
    "          'Passport Information': 8,\n",
    "          'Transport UKR CH': 9}\n",
    "df['cluster_names'] = df['cluster'].apply(lambda x: list(class_name_dict.keys())[list(class_name_dict.values()).index(x)])\n",
    "df['week']=df['messageDatetime'].apply(lambda x: pd.to_datetime(x).isocalendar()[1])\n",
    "messages_per_week_dict = dict(df.value_counts(\"week\"))\n",
    "df_value_counts = df.value_counts([\"cluster_names\", \"week\"]).reset_index()\n",
    "df_value_counts.columns = [\"cluster_names\", \"week\", \"occurence_count\"]\n",
    "df_value_counts['occurence_count_norm'] = df_value_counts.apply(lambda x: x.occurence_count/list(messages_per_week_dict.values())[list(messages_per_week_dict.keys()).index(x.week)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "cluster_names=Transport UKR CH<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Transport UKR CH",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Transport UKR CH",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          1,
          36,
          21,
          54,
          58,
          55,
          55,
          68,
          77,
          65,
          67,
          80,
          81,
          70,
          90,
          78,
          79,
          70,
          102,
          101,
          103,
          103,
          91,
          84,
          75,
          74,
          62,
          56,
          72,
          54,
          75,
          55,
          68,
          52,
          59,
          69,
          47,
          21
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Banking<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Banking",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Banking",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          2,
          8,
          21,
          125,
          136,
          127,
          191,
          181,
          127,
          198,
          178,
          90,
          149,
          182,
          143,
          136,
          109,
          179,
          108,
          95,
          109,
          113,
          93,
          65,
          108,
          56,
          36,
          60,
          73,
          67,
          42,
          58,
          73,
          50,
          49,
          29,
          52,
          22
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=S Status<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "S Status",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "S Status",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          2,
          9,
          51,
          254,
          482,
          353,
          309,
          202,
          258,
          197,
          180,
          146,
          161,
          124,
          126,
          141,
          111,
          100,
          123,
          101,
          74,
          93,
          78,
          85,
          64,
          79,
          74,
          60,
          63,
          69,
          40,
          81,
          75,
          55,
          42,
          67,
          38,
          18
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Medical<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Medical",
         "line": {
          "color": "#ab63fa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Medical",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          3,
          24,
          44,
          98,
          238,
          245,
          166,
          187,
          225,
          235,
          182,
          203,
          152,
          172,
          175,
          104,
          178,
          167,
          205,
          171,
          102,
          199,
          83,
          125,
          96,
          97,
          67,
          108,
          139,
          132,
          111,
          131,
          134,
          100,
          143,
          124,
          109,
          63
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Passport Information<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Passport Information",
         "line": {
          "color": "#FFA15A",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Passport Information",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          5,
          13,
          76,
          162,
          230,
          139,
          116,
          80,
          99,
          104,
          85,
          115,
          86,
          114,
          54,
          66,
          75,
          65,
          61,
          60,
          85,
          60,
          81,
          80,
          62,
          58,
          55,
          66,
          54,
          45,
          37,
          58,
          67,
          45,
          34,
          25,
          38,
          11
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Complaints<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Complaints",
         "line": {
          "color": "#19d3f3",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Complaints",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          8,
          66,
          134,
          333,
          476,
          375,
          316,
          234,
          274,
          192,
          277,
          179,
          195,
          143,
          230,
          158,
          137,
          162,
          169,
          151,
          131,
          181,
          177,
          146,
          197,
          195,
          322,
          308,
          208,
          238,
          189,
          209,
          229,
          251,
          262,
          220,
          241,
          78
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Train Travel<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Train Travel",
         "line": {
          "color": "#FF6692",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Train Travel",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          1,
          24,
          92,
          185,
          134,
          109,
          58,
          86,
          97,
          83,
          106,
          111,
          124,
          166,
          208,
          140,
          133,
          161,
          99,
          107,
          59,
          84,
          96,
          100,
          103,
          99,
          54,
          93,
          80,
          70,
          48,
          63,
          53,
          43,
          50,
          60,
          39,
          22
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Asylum/Volunteering<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Asylum/Volunteering",
         "line": {
          "color": "#B6E880",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Asylum/Volunteering",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          66,
          184,
          419,
          360,
          298,
          218,
          183,
          161,
          127,
          147,
          101,
          117,
          74,
          122,
          77,
          71,
          59,
          75,
          70,
          66,
          80,
          71,
          74,
          55,
          54,
          63,
          53,
          45,
          36,
          38,
          40,
          31,
          41,
          47,
          51,
          57,
          25
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Veterinarian<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Veterinarian",
         "line": {
          "color": "#FF97FF",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Veterinarian",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          21,
          64,
          167,
          247,
          239,
          144,
          126,
          153,
          97,
          102,
          104,
          80,
          50,
          60,
          67,
          68,
          56,
          51,
          64,
          41,
          99,
          64,
          47,
          61,
          51,
          42,
          53,
          43,
          21,
          44,
          55,
          51,
          88,
          36,
          44,
          37,
          16
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Accomodation<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Accomodation",
         "line": {
          "color": "#FECB52",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Accomodation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          14,
          60,
          176,
          279,
          232,
          157,
          127,
          145,
          114,
          110,
          88,
          108,
          77,
          74,
          60,
          66,
          68,
          112,
          68,
          62,
          77,
          60,
          57,
          80,
          43,
          61,
          52,
          39,
          50,
          28,
          48,
          45,
          35,
          35,
          44,
          38,
          21
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "cluster_names"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cluster over time"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "week"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "occurence_count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(df_value_counts[df_value_counts.cluster_names != \"no_class\"].sort_values(['week']), x=\"week\", y=\"occurence_count\", color='cluster_names', title='Cluster over time')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df[df.uniqueIdentifier==\"https://t.me/refugeesinSwitzerland_165886\"].messageReactions.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(df.messageReactions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.messageReactions[0]==float('nan'):\n",
    "    print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.search(\"^The.*Spain$\", txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_reaction(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_reaction(reaction):\n",
    "    if isinstance(reaction, str):\n",
    "        m = re.findall('count=(.+?),', reaction)\n",
    "        m = list(map(int, m))\n",
    "        return sum(m)\n",
    "    else:\n",
    "        return float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reaction_count\"] = df.apply(lambda x: count_reaction(x.messageReactions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>messageSender</th>\n",
       "      <th>messageID</th>\n",
       "      <th>messageReplyID</th>\n",
       "      <th>messageDatetime</th>\n",
       "      <th>messageViews</th>\n",
       "      <th>messageForwards</th>\n",
       "      <th>messageReactions</th>\n",
       "      <th>messageText</th>\n",
       "      <th>cluster</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_5</th>\n",
       "      <th>prob_6</th>\n",
       "      <th>prob_7</th>\n",
       "      <th>prob_8</th>\n",
       "      <th>prob_9</th>\n",
       "      <th>uniqueIdentifier</th>\n",
       "      <th>uniqueIdentifierReply</th>\n",
       "      <th>cluster_names</th>\n",
       "      <th>week</th>\n",
       "      <th>reaction_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland</td>\n",
       "      <td>-1.001507e+12</td>\n",
       "      <td>1465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-09 11:54:20+00:00</td>\n",
       "      <td>349.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>–ó–∞–ø—Ä–æ—à—É—î–º–æ –≤–∞—Å –Ω–∞ –≤–µ–±—ñ–Ω–∞—Ä: –ï–ù–Ü–û–°–¢–ò–õ–¨. –û—Å–æ–±–∏—Å—Ç–∞...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.806893e-04</td>\n",
       "      <td>2.828152e-04</td>\n",
       "      <td>8.368974e-06</td>\n",
       "      <td>4.737701e-04</td>\n",
       "      <td>7.745345e-04</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_1465</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland</td>\n",
       "      <td>-1.001507e+12</td>\n",
       "      <td>1464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-08 17:11:10+00:00</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9 –ª–∏—Å—Ç–æ–ø–∞–¥–∞, –≤ –î–µ–Ω—å —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –ø–∏—Å–µ–º–Ω–æ—Å—Ç—ñ —Ç–∞ ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.456777e-73</td>\n",
       "      <td>2.239044e-73</td>\n",
       "      <td>4.911532e-137</td>\n",
       "      <td>2.256454e-73</td>\n",
       "      <td>8.786752e-72</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_1464</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland</td>\n",
       "      <td>-1.001507e+12</td>\n",
       "      <td>1463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-08 16:32:02+00:00</td>\n",
       "      <td>557.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>–ó–∞–ø—Ä–æ—à—É—î–º–æ –≤–∞—Å —É —Ü—å–æ–º—É —Ä–æ—Ü—ñ –Ω–∞ —Ç—Ä–∏ –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –∑—É...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.655554e-23</td>\n",
       "      <td>4.205600e-23</td>\n",
       "      <td>3.461776e-24</td>\n",
       "      <td>7.345640e-23</td>\n",
       "      <td>1.251607e-22</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_1463</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland</td>\n",
       "      <td>-1.001507e+12</td>\n",
       "      <td>1462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-08 13:26:26+00:00</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>–ó–∞ –ø—ñ–≤–≥–æ–¥–∏–Ω–∏ –ø–æ—á–∏–Ω–∞—î–º–æ: Campax –∑–∞–ø—Ä–æ—à—É—î –¢–µ–±–µ –ø...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.784245e-53</td>\n",
       "      <td>4.426106e-53</td>\n",
       "      <td>1.945072e-73</td>\n",
       "      <td>7.376132e-53</td>\n",
       "      <td>1.569924e-18</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_1462</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland</td>\n",
       "      <td>-1.001507e+12</td>\n",
       "      <td>1461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-08 13:25:25+00:00</td>\n",
       "      <td>538.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BCUE —Å—É–º—ñ—Å–Ω–æ –∑ PwC PricewaterhouseCoopers –ø—Ä–æ–≤...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295806e-135</td>\n",
       "      <td>5.288591e-71</td>\n",
       "      <td>7.583213e-137</td>\n",
       "      <td>3.823073e-135</td>\n",
       "      <td>7.425516e-57</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_1461</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287958</th>\n",
       "      <td>https://t.me/SwissUA</td>\n",
       "      <td>1.264982e+09</td>\n",
       "      <td>307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-26 18:54:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n",
       "      <td>–£ –Ω–∞—Å —â–µ —î 6 –¥–Ω—ñ–≤ - –º–∏ —Å–ø—Ä–∞–≤–∏–º–æ—Å—å ‚ù§Ô∏è</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.259132e-170</td>\n",
       "      <td>5.314623e-170</td>\n",
       "      <td>8.549347e-175</td>\n",
       "      <td>7.095355e-170</td>\n",
       "      <td>4.591511e-152</td>\n",
       "      <td>https://t.me/SwissUA_307</td>\n",
       "      <td>https://t.me/SwissUA_n</td>\n",
       "      <td>S Status</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287959</th>\n",
       "      <td>https://t.me/SwissUA</td>\n",
       "      <td>3.368129e+08</td>\n",
       "      <td>306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-26 18:41:02+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n",
       "      <td>–µ—Å–ª–∏ –≤—ã–¥–∞–µ—Ç –æ—à–∏–±–∫—É –ø—Ä–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–∏, –ø–æ–¥–æ–∂–¥–∏—Ç...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.113500e-02</td>\n",
       "      <td>1.234151e-02</td>\n",
       "      <td>1.659530e-04</td>\n",
       "      <td>2.000865e-02</td>\n",
       "      <td>2.937823e-02</td>\n",
       "      <td>https://t.me/SwissUA_306</td>\n",
       "      <td>https://t.me/SwissUA_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287960</th>\n",
       "      <td>https://t.me/SwissUA</td>\n",
       "      <td>4.852700e+08</td>\n",
       "      <td>305</td>\n",
       "      <td>301.0</td>\n",
       "      <td>2022-02-26 18:39:36+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>–ï—Å–ª–∏ –ø–µ—Ç–∏—Ü–∏—è –Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è, –∑–Ω–∞—á–∏—Ç –æ—á–µ–Ω—å –º–Ω–æ–≥...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.001051e-129</td>\n",
       "      <td>2.930032e-121</td>\n",
       "      <td>1.000877e-130</td>\n",
       "      <td>8.587486e-129</td>\n",
       "      <td>2.994915e-115</td>\n",
       "      <td>https://t.me/SwissUA_305</td>\n",
       "      <td>https://t.me/SwissUA_301</td>\n",
       "      <td>no_class</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287961</th>\n",
       "      <td>https://t.me/SwissUA</td>\n",
       "      <td>3.368129e+08</td>\n",
       "      <td>304</td>\n",
       "      <td>301.0</td>\n",
       "      <td>2022-02-26 18:09:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n",
       "      <td>—Å–ø–∞—Å–∏–±–æ</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.534590e-118</td>\n",
       "      <td>1.942554e-112</td>\n",
       "      <td>1.320957e-121</td>\n",
       "      <td>4.284275e-110</td>\n",
       "      <td>9.667967e-92</td>\n",
       "      <td>https://t.me/SwissUA_304</td>\n",
       "      <td>https://t.me/SwissUA_301</td>\n",
       "      <td>no_class</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287962</th>\n",
       "      <td>https://t.me/SwissUA</td>\n",
       "      <td>4.852700e+08</td>\n",
       "      <td>303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-26 18:06:58+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n",
       "      <td>–ú–∏ –æ—Ç—Ä–∏–º–∞–ª–∏ —Å–≤—ñ—Ñ—Ç, –ø—Ä–æ–¥–æ–≤–∂—É—î–º–æ</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.634377e-10</td>\n",
       "      <td>2.199271e-11</td>\n",
       "      <td>6.454256e-16</td>\n",
       "      <td>9.924997e-12</td>\n",
       "      <td>2.202697e-11</td>\n",
       "      <td>https://t.me/SwissUA_303</td>\n",
       "      <td>https://t.me/SwissUA_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287963 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chat  messageSender  \\\n",
       "0       https://t.me/campax_ukraine_help_switzerland  -1.001507e+12   \n",
       "1       https://t.me/campax_ukraine_help_switzerland  -1.001507e+12   \n",
       "2       https://t.me/campax_ukraine_help_switzerland  -1.001507e+12   \n",
       "3       https://t.me/campax_ukraine_help_switzerland  -1.001507e+12   \n",
       "4       https://t.me/campax_ukraine_help_switzerland  -1.001507e+12   \n",
       "...                                              ...            ...   \n",
       "287958                          https://t.me/SwissUA   1.264982e+09   \n",
       "287959                          https://t.me/SwissUA   3.368129e+08   \n",
       "287960                          https://t.me/SwissUA   4.852700e+08   \n",
       "287961                          https://t.me/SwissUA   3.368129e+08   \n",
       "287962                          https://t.me/SwissUA   4.852700e+08   \n",
       "\n",
       "        messageID  messageReplyID            messageDatetime  messageViews  \\\n",
       "0            1465             NaN  2022-11-09 11:54:20+00:00         349.0   \n",
       "1            1464             NaN  2022-11-08 17:11:10+00:00         600.0   \n",
       "2            1463             NaN  2022-11-08 16:32:02+00:00         557.0   \n",
       "3            1462             NaN  2022-11-08 13:26:26+00:00         561.0   \n",
       "4            1461             NaN  2022-11-08 13:25:25+00:00         538.0   \n",
       "...           ...             ...                        ...           ...   \n",
       "287958        307             NaN  2022-02-26 18:54:00+00:00           NaN   \n",
       "287959        306             NaN  2022-02-26 18:41:02+00:00           NaN   \n",
       "287960        305           301.0  2022-02-26 18:39:36+00:00           NaN   \n",
       "287961        304           301.0  2022-02-26 18:09:06+00:00           NaN   \n",
       "287962        303             NaN  2022-02-26 18:06:58+00:00           NaN   \n",
       "\n",
       "        messageForwards                                   messageReactions  \\\n",
       "0                   0.0                                                NaN   \n",
       "1                   3.0                                                NaN   \n",
       "2                   3.0                                                NaN   \n",
       "3                   0.0                                                NaN   \n",
       "4                   8.0                                                NaN   \n",
       "...                 ...                                                ...   \n",
       "287958              NaN  MessageReactions(results=[ReactionCount(reacti...   \n",
       "287959              NaN  MessageReactions(results=[ReactionCount(reacti...   \n",
       "287960              NaN                                                NaN   \n",
       "287961              NaN  MessageReactions(results=[ReactionCount(reacti...   \n",
       "287962              NaN  MessageReactions(results=[ReactionCount(reacti...   \n",
       "\n",
       "                                              messageText  cluster  ...  \\\n",
       "0       –ó–∞–ø—Ä–æ—à—É—î–º–æ –≤–∞—Å –Ω–∞ –≤–µ–±—ñ–Ω–∞—Ä: –ï–ù–Ü–û–°–¢–ò–õ–¨. –û—Å–æ–±–∏—Å—Ç–∞...       -1  ...   \n",
       "1       9 –ª–∏—Å—Ç–æ–ø–∞–¥–∞, –≤ –î–µ–Ω—å —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –ø–∏—Å–µ–º–Ω–æ—Å—Ç—ñ —Ç–∞ ...       -1  ...   \n",
       "2       –ó–∞–ø—Ä–æ—à—É—î–º–æ –≤–∞—Å —É —Ü—å–æ–º—É —Ä–æ—Ü—ñ –Ω–∞ —Ç—Ä–∏ –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –∑—É...       -1  ...   \n",
       "3       –ó–∞ –ø—ñ–≤–≥–æ–¥–∏–Ω–∏ –ø–æ—á–∏–Ω–∞—î–º–æ: Campax –∑–∞–ø—Ä–æ—à—É—î –¢–µ–±–µ –ø...       -1  ...   \n",
       "4       BCUE —Å—É–º—ñ—Å–Ω–æ –∑ PwC PricewaterhouseCoopers –ø—Ä–æ–≤...       -1  ...   \n",
       "...                                                   ...      ...  ...   \n",
       "287958               –£ –Ω–∞—Å —â–µ —î 6 –¥–Ω—ñ–≤ - –º–∏ —Å–ø—Ä–∞–≤–∏–º–æ—Å—å ‚ù§Ô∏è        5  ...   \n",
       "287959  –µ—Å–ª–∏ –≤—ã–¥–∞–µ—Ç –æ—à–∏–±–∫—É –ø—Ä–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–∏, –ø–æ–¥–æ–∂–¥–∏—Ç...       -1  ...   \n",
       "287960  –ï—Å–ª–∏ –ø–µ—Ç–∏—Ü–∏—è –Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è, –∑–Ω–∞—á–∏—Ç –æ—á–µ–Ω—å –º–Ω–æ–≥...       -1  ...   \n",
       "287961                                            —Å–ø–∞—Å–∏–±–æ       -1  ...   \n",
       "287962                     –ú–∏ –æ—Ç—Ä–∏–º–∞–ª–∏ —Å–≤—ñ—Ñ—Ç, –ø—Ä–æ–¥–æ–≤–∂—É—î–º–æ       -1  ...   \n",
       "\n",
       "               prob_5         prob_6         prob_7         prob_8  \\\n",
       "0        1.806893e-04   2.828152e-04   8.368974e-06   4.737701e-04   \n",
       "1        4.456777e-73   2.239044e-73  4.911532e-137   2.256454e-73   \n",
       "2        2.655554e-23   4.205600e-23   3.461776e-24   7.345640e-23   \n",
       "3        2.784245e-53   4.426106e-53   1.945072e-73   7.376132e-53   \n",
       "4       1.295806e-135   5.288591e-71  7.583213e-137  3.823073e-135   \n",
       "...               ...            ...            ...            ...   \n",
       "287958  4.259132e-170  5.314623e-170  8.549347e-175  7.095355e-170   \n",
       "287959   1.113500e-02   1.234151e-02   1.659530e-04   2.000865e-02   \n",
       "287960  3.001051e-129  2.930032e-121  1.000877e-130  8.587486e-129   \n",
       "287961  1.534590e-118  1.942554e-112  1.320957e-121  4.284275e-110   \n",
       "287962   7.634377e-10   2.199271e-11   6.454256e-16   9.924997e-12   \n",
       "\n",
       "               prob_9                                   uniqueIdentifier  \\\n",
       "0        7.745345e-04  https://t.me/campax_ukraine_help_switzerland_1465   \n",
       "1        8.786752e-72  https://t.me/campax_ukraine_help_switzerland_1464   \n",
       "2        1.251607e-22  https://t.me/campax_ukraine_help_switzerland_1463   \n",
       "3        1.569924e-18  https://t.me/campax_ukraine_help_switzerland_1462   \n",
       "4        7.425516e-57  https://t.me/campax_ukraine_help_switzerland_1461   \n",
       "...               ...                                                ...   \n",
       "287958  4.591511e-152                           https://t.me/SwissUA_307   \n",
       "287959   2.937823e-02                           https://t.me/SwissUA_306   \n",
       "287960  2.994915e-115                           https://t.me/SwissUA_305   \n",
       "287961   9.667967e-92                           https://t.me/SwissUA_304   \n",
       "287962   2.202697e-11                           https://t.me/SwissUA_303   \n",
       "\n",
       "                                 uniqueIdentifierReply  cluster_names  week  \\\n",
       "0       https://t.me/campax_ukraine_help_switzerland_n       no_class    45   \n",
       "1       https://t.me/campax_ukraine_help_switzerland_n       no_class    45   \n",
       "2       https://t.me/campax_ukraine_help_switzerland_n       no_class    45   \n",
       "3       https://t.me/campax_ukraine_help_switzerland_n       no_class    45   \n",
       "4       https://t.me/campax_ukraine_help_switzerland_n       no_class    45   \n",
       "...                                                ...            ...   ...   \n",
       "287958                          https://t.me/SwissUA_n       S Status     8   \n",
       "287959                          https://t.me/SwissUA_n       no_class     8   \n",
       "287960                        https://t.me/SwissUA_301       no_class     8   \n",
       "287961                        https://t.me/SwissUA_301       no_class     8   \n",
       "287962                          https://t.me/SwissUA_n       no_class     8   \n",
       "\n",
       "        reaction_count  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "...                ...  \n",
       "287958             1.0  \n",
       "287959             1.0  \n",
       "287960             0.0  \n",
       "287961             1.0  \n",
       "287962             1.0  \n",
       "\n",
       "[287963 rows x 25 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.comparis.ch/ 12 Tips —è–∫ –∞—Ä–µ–Ω–¥—É–≤–∞—Ç–∏ –∂–∏—Ç–ª–æ –≤—ñ–¥ Comparis: https://www.comparis.ch/immobilien/wohnungssuche/wohnungssuche-tipps-tricks',\n",
       " '–°–∞–π—Ç –ø–æ—à—É–∫—É –∞—Ä–µ–Ω–¥–∏ –∂–∏—Ç–ª–∞: https://www.homegate.ch/de',\n",
       " '–ü–æ–º—ñ—á–Ω–∏—Ü—è –ø–æ –≥–æ—Å–ø–æ–¥–∞—Ä—Å—Ç–≤—É –∑ –ø—Ä–æ–∂–∏–≤–∞–Ω–Ω—è–º+–¥–æ–ø–æ–º–æ–≥–∞ –∑ –¥–∏—Ç–∏–Ω–æ—é –ø–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ—Å—Ç—ñ ( 4 —Ä–æ–∫–∏, —Å–ø–æ–∫—ñ–π–Ω–∏–π, 4 —Ä–∞–∑–∏ –≤ —Ç–∏–∂–¥–µ–Ω—å –≤—ñ–¥–≤—ñ–¥—É—î –¥–∏—Ç—è—á–∏–π —Å–∞–¥–æ–∫). –ù–∞–¥–∞—î—Ç—å—Å—è –æ–∫—Ä–µ–º–∞ –∫—ñ–º–Ω–∞—Ç–∞ –∑ —Å–∞–Ω–≤—É–∑–ª–æ–º, —Ö–∞—Ä—á—É–≤–∞–Ω–Ω—è, –¥–æ–ø–æ–º–æ–≥–∞ –∑ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—è–º —Å—Ç–∞—Ç—É—Å—É S. –ê–±–æ –∂ –ø—Ä–∏—Ö–æ–¥—è—â—É –ø–æ–º—ñ—á–Ω–∏—Ü—é –¥–µ–∫—ñ–ª—å–∫–∞ —Ä–∞–∑ –Ω–∞ —Ç–∏–∂–¥–µ–Ω—å. –õ–æ–∫–∞—Ü—ñ—è - Adliswil 8134. –î–µ—Ç–∞–ª—ñ –≤ –ü–ü –±—É–¥—å-–ª–∞—Å–∫–∞ https://www.facebook.com/olya.olga.167',\n",
       " '–ü–æ–º—ñ—á–Ω–∏—Ü—è –ø–æ –≥–æ—Å–ø–æ–¥–∞—Ä—Å—Ç–≤—É –∑ –ø—Ä–æ–∂–∏–≤–∞–Ω–Ω—è–º+–¥–æ–ø–æ–º–æ–≥–∞ –∑ –¥–∏—Ç–∏–Ω–æ—é –ø–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ—Å—Ç—ñ ( 4 —Ä–æ–∫–∏, —Å–ø–æ–∫—ñ–π–Ω–∏–π, 4 —Ä–∞–∑–∏ –≤ —Ç–∏–∂–¥–µ–Ω—å –≤—ñ–¥–≤—ñ–¥—É—î –¥–∏—Ç—è—á–∏–π —Å–∞–¥–æ–∫). –ù–∞–¥–∞—î—Ç—å—Å—è –æ–∫—Ä–µ–º–∞ –∫—ñ–º–Ω–∞—Ç–∞ –∑ —Å–∞–Ω–≤—É–∑–ª–æ–º, —Ö–∞—Ä—á—É–≤–∞–Ω–Ω—è, –¥–æ–ø–æ–º–æ–≥–∞ –∑ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—è–º —Å—Ç–∞—Ç—É—Å—É S. –ê–±–æ –∂ –ø—Ä–∏—Ö–æ–¥—è—â—É –ø–æ–º—ñ—á–Ω–∏—Ü—é –¥–µ–∫—ñ–ª—å–∫–∞ —Ä–∞–∑ –Ω–∞ —Ç–∏–∂–¥–µ–Ω—å. –õ–æ–∫–∞—Ü—ñ—è - Adliswil 8134. –î–µ—Ç–∞–ª—ñ –≤ –ü–ü –±—É–¥—å-–ª–∞—Å–∫–∞ https://www.facebook.com/olya.olga.167',\n",
       " '**–ò—â–µ—Ç–µ –∫–≤–∞—Ä—Ç–∏—Ä—É? –•–æ—Ç–∏—Ç–µ –æ—Ç–¥–µ–ª—å–Ω–æ–µ –∂–∏–ª—å—ë? –ö–∞–∫ —Å–Ω—è—Ç—å –µ–≥–æ –≤ —Ä–∞–∑—É–º–Ω—ã–µ —Å—Ä–æ–∫–∏? **–≠—Ç–∏ –≤–æ–ø—Ä–æ—Å—ã –æ–±—Å—É–¥–∏–ª–∏ –Ω–∞ –ø—Ä–æ—à–ª–æ–π –Ω–µ–¥–µ–ª–µ –Ω–∞ –≤—Å—Ç—Ä–µ—á–∞—Ö –≤ –ë–µ—Ä–Ω–µ. –°–ø–∞—Å–∏–±–æ Elisabeth –∏ –û–ª—å–≥–µ! –†–∞–∑–æ–±—Ä–∞–ª–∏: 1. –®–∞–≥–∏ –∞—Ä–µ–Ω–¥—ã –∫–≤ –≤ CH* 2. –°–∞–π—Ç—ã –æ–±—ä—è–≤ –æ–± –∞—Ä–µ–Ω–¥–µ –∫–≤ 3. –í–∏–¥—ã –∞—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª–µ–π 4. –û–±—ä—è–≤–∞ –æ –∫–≤: —á—Ç–æ –≤–∞–∂–Ω–æ 5. 1-–π –æ—Ç–∫–ª–∏–∫ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ 6. –ü—Ä–æ—Å–º–æ—Ç—Ä –∫–≤: - –≤–∏–¥—ã –ø–æ—Å—Ä–µ–¥–Ω–∏–∫–æ–≤ - –≤–æ–ø—Ä–æ—Å—ã –∫ –Ω–∏–º 7. –ó–∞—è–≤–∫–∞ –Ω–∞ –∫–≤ (–¥–æ—Å—å–µ) - –≤–∞—à–∞ –∏—Å—Ç–æ—Ä–∏—è –≤ –ø–∏—Å—å–º–µ - —Ñ–æ—Ç–æ –∏ –ø—Ä–æ—á–µ–µ - –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—É–ª—è—Ä–∞ 8. –°—Ç—Ä–∞—Ö–æ–≤–∫–∏ –¥–ª—è –¥–æ–≥–æ–≤–æ—Ä–∞ 9. –í–∏–¥—ã –∫–≤ –≤ CH 10. –ö–∞–∫–∞—è –∫–≤ –ø–æ–¥—Ö–æ–¥–∏—Ç –≤–∞–º **–í–ù–ò–ú–ê–ù–ò–ï! **–ó–∞–≤—Ç—Ä–∞ —Å–æ—Å—Ç–æ–∏—Ç—Å—è 3-—è –≤—Å—Ç—Ä–µ—á–∞, –≥–¥–µ –±—É–¥–µ–º –ø–æ–≤—Ç–æ—Ä—è—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤ (30 –º–∏–Ω). –û—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è (1,5 —á–∞—Å–∞) –ø–æ—Å–≤—è—Ç–∏–º —Ä–∞–∑–±–æ—Ä—É –æ–±—ä—è–≤ –∏ –ø–æ–¥–∞—á–µ –∑–∞—è–≤–æ–∫ –Ω–∞ –∏—Ö. –ü—Ä–∏—Ö–æ–¥–∏—Ç–µ —Å —Ñ–æ—Ä–º—É–ª—è—Ä–∞–º–∏ –∏–ª–∏ —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º–∏ –∏–ª–∏ —Å–º–∞—Ä—Ç—Ñ–æ–Ω–∞–º–∏. –ë—É–¥–µ–º –ø–∏—Å–∞—Ç—å –ø–∏—Å—å–º–∞ –∏ –ø–æ–¥–∞–≤–∞—Ç—å –∑–∞—è–≤–∫–∏ –≤–º–µ—Å—Ç–µ. –í–æ–ø—Ä–æ—Å—ã? –ü–∏—à–∏—Ç–µ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ö –Ω–∏–∂–µ –∏–ª–∏ –º–Ω–µ @VladiSwiss –î–æ –∑–∞–≤—Ç—Ä–∞! –í—Å—Ç—Ä–µ—á–∞ –ø–æ –∞–¥—Ä–µ—Å—É: https://goo.gl/maps/tauZZE5XZgUJM7Hs7 * CH = Confoederatio Helvetica - —ç—Ç–æ –ª–∞—Ç–∏–Ω—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –®–≤–µ–π—Ü–∞—Ä—Å–∫–æ–π –ö–æ–Ω—Ñ–µ–¥–µ—Ä–∞—Ü–∏–∏',\n",
       " '18. –û –∂–∏–ª—å–µ (–∫–∞–∫ –Ω–∞–π—Ç–∏, –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∞—Ä–µ–Ω–¥—ã)',\n",
       " '–©–æ —Ç–∞–∫–µ –≤—Ç—Ä–∞—Ç–∞ –¥–æ–º—É —ñ —è–∫ —ó—ó –ø–µ—Ä–µ–∂–∏—Ç–∏ –ó –ø–æ—á–∞—Ç–∫–æ–º –ø–æ–≤–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω–æ—ó –≤—ñ–π–Ω–∏ –ø–æ–Ω—è—Ç—Ç—è –¥–æ–º—É –∑–Ω–∞—á–Ω–æ —Ä–æ–∑—à–∏—Ä–∏–ª–æ—Å—è. –¶–µ —ñ —Ñ—ñ–∑–∏—á–Ω–∏–π –±—É–¥–∏–Ω–æ–∫, —É —è–∫–æ–º—É –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –¥–æ—Ä–æ–≥—ñ –Ω–∞–º —Ä–µ—á—ñ, —ñ —Ä—ñ–¥–Ω–µ –º—ñ—Å—Ç–æ, –¥–µ –º–∏ –≤–∏—Ä–æ—Å–ª–∏, —ñ –æ—Ç–æ—á–µ–Ω–Ω—è –±–ª–∏–∑—å–∫–∏—Ö –¥—Ä—É–∑—ñ–≤, —ñ –Ω–µ–∑–Ω–∞–π–æ–º—ñ –Ω–∞–º –ª—é–¥–∏, —è–∫—ñ –∑–∞—Ö–∏—â–∞—é—Ç—å –∫—Ä–∞—ó–Ω—É –≤ –ª–∞–≤–∞—Ö –ó–°–£. –ë–∞–≥–∞—Ç–æ —É–∫—Ä–∞—ó–Ω—Ü—ñ–≤ –≤—Ç—Ä–∞—Ç–∏–ª–∏ —Å–≤—ñ–π –¥—ñ–º —á–µ—Ä–µ–∑ –ø–æ–≤–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω–µ –≤—Ç–æ—Ä–≥–Ω–µ–Ω–Ω—è –∞–±–æ –≤–∏—ó—Ö–∞–ª–∏ –∑ –£–∫—Ä–∞—ó–Ω–∏, —Å—É–º—É—é—Ç—å –∑–∞ —Å–≤–æ—ó–º–∏ –∫–≤–∞—Ä—Ç–∏—Ä–∞–º–∏ —Ç–∞ –≤–∏–º—É—à–µ–Ω—ñ –æ–±–ª–∞—à—Ç–æ–≤—É–≤–∞—Ç–∏ –∂–∏—Ç—Ç—è –∑–∞–Ω–æ–≤–æ. –ó–∞ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–º–∏ –¥–∞–Ω–∏–º–∏ –≤—ñ–¥ –∑–∞—Å—Ç—É–ø–Ω–∏—Ü—ñ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç—É –∂–∏—Ç–ª–æ–≤–æ—ó –ø–æ–ª—ñ—Ç–∏–∫–∏ —Ç–∞ –±–ª–∞–≥–æ—É—Å—Ç—Ä–æ—é –ú—ñ–Ω—ñ—Å—Ç–µ—Ä—Å—Ç–≤–∞ —Ä–æ–∑–≤–∏—Ç–∫—É –≥—Ä–æ–º–∞–¥ —ñ —Ç–µ—Ä–∏—Ç–æ—Ä—ñ–π –°–≤—ñ—Ç–ª–∞–Ω–∏ –°—Ç–∞—Ä—Ü–µ–≤–æ—ó, –≤ –£–∫—Ä–∞—ó–Ω—ñ —Å—Ç–∞–Ω–æ–º –Ω–∞ 1 —á–µ—Ä–≤–Ω—è 3,5 –º–ª–Ω —É–∫—Ä–∞—ó–Ω—Ü—ñ–≤ –º–∞—é—Ç—å –ø–æ—à–∫–æ–¥–∂–µ–Ω–µ –∞–±–æ –∑—Ä—É–π–Ω–æ–≤–∞–Ω–µ –∂–∏—Ç–ª–æ. –ö—Ä—ñ–º –∂–∏—Ç–ª–∞, —É–∫—Ä–∞—ó–Ω—Ü—ñ –≤—Ç—Ä–∞—á–∞—é—Ç—å –±–ª–∏–∑—å–∫–∏—Ö –ª—é–¥–µ–π, –ø–æ–≤—Å—è–∫–¥–µ–Ω–Ω–∏–π —Ä–∏—Ç–º –∂–∏—Ç—Ç—è, —Å–ø–æ–∫—ñ–π —ñ –±–∞–∑–æ–≤–µ –≤—ñ–¥—á—É—Ç—Ç—è –±–µ–∑–ø–µ–∫–∏. –°–ø—ñ–ª—å–Ω–æ –∑ –û–û–ù –ñ—ñ–Ω–∫–∏ –º–∏ –ø–æ–≥–æ–≤–æ—Ä–∏–ª–∏ –∑ –ø—Å–∏—Ö–æ–ª–æ–≥–∏–Ω–µ—é SafeWomenHUB –¢–µ—Ç—è–Ω–æ—é –§—Ä–∞–Ω—á—É–∫ –ø—Ä–æ –≤—Ç—Ä–∞—Ç—É –∑–≤–∏—á–Ω–æ–≥–æ –¥–ª—è –Ω–∞—Å —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞, —è–∫ —ó—ó –ø–µ—Ä–µ–∂–∏—Ç–∏ —ñ —è–∫ –ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞—Ç–∏ —Ç–∏—Ö, —Ö—Ç–æ –ø–µ—Ä–µ–±—É–≤–∞—î –ø–æ—Ä—É—á, –¥–µ—Ç–∞–ª—ñ: https://www.wonderzine.com.ua/wonderzine/life/life/11757-scho-take-vtrata-domu-i-yak-yiyi-perezhiti #StandwithUkraine',\n",
       " '–ò–Ω–æ–≥–¥–∞ –∏ –º–µ—Å—Ç–Ω—ã–µ –∏—â—É—Ç –∫–≤–∞—Ä—Ç–∏—Ä—É –º–µ—Å—è—Ü–∞–º–∏ –∏ –¥–∞–∂–µ –≥–æ–¥–∞–º–∏ –∏–º–µ—è —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Ä–∞–±–æ—á–∏–π –∫–æ—Ç–Ω—Ç—Ä–∞–∫—Ç –∏ –ø–æ–ª—É—á–∞—é—Ç –¥–µ—Å—è—Ç–∫–∞–º–∏ –æ—Ç–∫–∞–∑—ã.',\n",
       " '82 –∫–≤–∞—Ä—Ç–∏—Ä—ã –æ—Ç–∫–∞–∑–∞–ª–∏?üò¨',\n",
       " '–ù—É –∏ —á–µ–≥–æ –≤—ã –ø–µ—Ä–µ–∂–∏–≤–∞–µ—Ç–µ? –ú–æ–∂–µ—Ç –∫–∞–∫ —Ä–∞–∑ –≤–∞–º –ø–æ–¥–±–∏—Ä–∞—é—Ç –±–æ–ª–µ–µ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–µ –∂–∏–ª—å–µ.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[(df.cluster_names==\"Accomodation\")].nlargest(10, \"messageForwards\").messageText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Float64Index([27267.0, 17493.0, 13924.0, 13039.0, 11668.0, 11448.0, 11071.0,\\n              10563.0,  9478.0,  9384.0],\\n             dtype='float64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universit√§t Z√ºrich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[df\u001b[39m.\u001b[39;49mmessageForwards\u001b[39m.\u001b[39;49mnlargest(\u001b[39m10\u001b[39;49m)]\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/frame.py:3810\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3808\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3809\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3810\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3812\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/indexes/base.py:6111\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6109\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6111\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6113\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6115\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/indexes/base.py:6171\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6169\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6170\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 6171\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6173\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   6174\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Float64Index([27267.0, 17493.0, 13924.0, 13039.0, 11668.0, 11448.0, 11071.0,\\n              10563.0,  9478.0,  9384.0],\\n             dtype='float64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "df[df.messageForwards.nlargest(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model after merge topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BERTopic.load(\"../models/BERTopic100CharMin2500CharMax_10Classes/merge_topics/BERTopicmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probabilities = model.fit_transform(docs[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_representative_docs().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"../models/BERTopic100CharMin2500CharMax_10Classes/merge_topics/representative_docs.xlsx\", engine='xlsxwriter')\n",
    "for i in model.get_representative_docs().keys():\n",
    "    print(i)\n",
    "    df = pd.DataFrame(model.get_representative_docs()[i], columns=['message'])\n",
    "    df.to_excel(writer, sheet_name=model.get_topic_info()[model.get_topic_info()['Topic']==i]['Name'].values[0][:31])\n",
    "writer.save()\n",
    "model.get_topic_info().to_csv(f\"../models/BERTopic100CharMin2500CharMax_10Classes/merge_topics/topic_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=BERTopic.load(\"../models/BERTopic100CharMin2500CharMax_20Classes/BERTopicmodel\")\n",
    "with open('../data/BERTopicInput100CharMin2500CharMax.csv') as file:\n",
    "    lines = file.readlines()\n",
    "    docs = [line.rstrip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics2, probabilities2 = model2.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../models/BERTopic100CharMin2500CharMax_20Classes/probabilities.pkl\",'wb') as f:\n",
    "    pickle.dump(probabilities2, f)\n",
    "with open(\"../models/BERTopic100CharMin2500CharMax_20Classes/topics.pkl\",'wb') as f:\n",
    "    pickle.dump(topics2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/BERTopic100CharMin2500CharMax_20Classes/topics.pkl\",'rb') as f:\n",
    "    x = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 93.8M/1.12G [00:05<01:22, 12.3MB/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universit√§t Z√ºrich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X61sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(img_folder, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X61sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39m'\u001b[39m\u001b[39mFlickr8k_Dataset.zip\u001b[39m\u001b[39m'\u001b[39m):   \u001b[39m#Download dataset if does not exist\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X61sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     util\u001b[39m.\u001b[39;49mhttp_get(\u001b[39m'\u001b[39;49m\u001b[39mhttps://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mFlickr8k_Dataset.zip\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X61sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     util\u001b[39m.\u001b[39mhttp_get(\u001b[39m'\u001b[39m\u001b[39mhttps://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFlickr8k_text.zip\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X61sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m folder, file \u001b[39min\u001b[39;00m [(img_folder, \u001b[39m'\u001b[39m\u001b[39mFlickr8k_Dataset.zip\u001b[39m\u001b[39m'\u001b[39m), (caps_folder, \u001b[39m'\u001b[39m\u001b[39mFlickr8k_text.zip\u001b[39m\u001b[39m'\u001b[39m)]:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/sentence_transformers/util.py:285\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, path)\u001b[0m\n\u001b[1;32m    283\u001b[0m total \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(content_length) \u001b[39mif\u001b[39;00m content_length \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    284\u001b[0m progress \u001b[39m=\u001b[39m tqdm(unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m, total\u001b[39m=\u001b[39mtotal, unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 285\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m req\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[1;32m    286\u001b[0m     \u001b[39mif\u001b[39;00m chunk: \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    287\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/urllib3/response.py:627\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 627\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    629\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    630\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/urllib3/response.py:566\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    563\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    565\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 566\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/urllib3/response.py:532\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    530\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    531\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/http/client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 463\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    464\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    465\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/http/client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    502\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    504\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    509\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Flickr 8k images\n",
    "img_folder = 'photos/'\n",
    "caps_folder = 'captions/'\n",
    "if not os.path.exists(img_folder) or len(os.listdir(img_folder)) == 0:\n",
    "    os.makedirs(img_folder, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists('Flickr8k_Dataset.zip'):   #Download dataset if does not exist\n",
    "        util.http_get('https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip', 'Flickr8k_Dataset.zip')\n",
    "        util.http_get('https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip', 'Flickr8k_text.zip')\n",
    "\n",
    "    for folder, file in [(img_folder, 'Flickr8k_Dataset.zip'), (caps_folder, 'Flickr8k_text.zip')]:\n",
    "        with zipfile.ZipFile(file, 'r') as zf:\n",
    "            for member in tqdm(zf.infolist(), desc='Extracting'):\n",
    "                zf.extract(member, folder)\n",
    "images = list(glob.glob('photos/Flicker8k_Dataset/*.jpg'))\n",
    "\n",
    "# Prepare dataframe\n",
    "captions = pd.read_csv(\"captions/Flickr8k.lemma.token.txt\",sep='\\t',names=[\"img_id\",\"img_caption\"])\n",
    "captions.img_id = captions.apply(lambda row: \"photos/Flicker8k_Dataset/\" + row.img_id.split(\".jpg\")[0] + \".jpg\", 1)\n",
    "captions = captions.groupby([\"img_id\"])[\"img_caption\"].apply(','.join).reset_index()\n",
    "captions = pd.merge(captions, pd.Series(images, name=\"img_id\"), on=\"img_id\")\n",
    "\n",
    "# Extract images together with their documents/captions\n",
    "images = captions.img_id.to_list()\n",
    "docs = captions.img_caption.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"wuhu\")\n",
    "model = SentenceTransformer('clip-ViT-B-32')\n",
    "print(\"wuhu\")\n",
    "# Prepare images\n",
    "batch_size = 32\n",
    "print(\"wuhu\")\n",
    "nr_iterations = int(np.ceil(len(images) / batch_size))\n",
    "print(\"wuhu\")\n",
    "# Embed images per batch\n",
    "embeddings = []\n",
    "for i in tqdm(range(nr_iterations)):\n",
    "    start_index = i * batch_size\n",
    "    end_index = (i * batch_size) + batch_size\n",
    "\n",
    "    images_to_embed = [Image.open(filepath) for filepath in images[start_index:end_index]]\n",
    "    img_emb = model.encode(images_to_embed, show_progress_bar=False)\n",
    "    embeddings.extend(img_emb.tolist())\n",
    "\n",
    "    # Close images\n",
    "    for image in images_to_embed:\n",
    "        image.close()\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model)\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings[:123])\n",
    "captions[\"Topic\"] = topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('refugeeAnalysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38bb9b58d9ea7be5a20c75aa0b89a578c4bb72fb8d5231ed76f30ad5b765ca05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
