{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from bertopic import BERTopic\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# TODO  check babyplot for 3D visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(input_file):\n",
    "    with open(input_file) as file:\n",
    "        lines = file.readlines()\n",
    "        text_to_analyse_list = [line.rstrip() for line in lines]\n",
    "    return text_to_analyse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(\"../data/BERTopicInput.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTopic(verbose=True, language=\"multilingual\", nr_topics=30) # vectorizer_model=vectorizer_model)#, nr_topics=20)\n",
    "topics, probs = model.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "# setting path\n",
    "sys.path.append('../src/BERTopic/')\n",
    "from runBERTopic import BERTopicAnalysis\n",
    "\n",
    "nr_topics_list = [\"auto\"]\n",
    "min_topic_size_list = [10,25,50,100,200,400,800,1000,1500]\n",
    "hbscan_min_cluster_size_list = [25,50,100,200]\n",
    "\n",
    "\n",
    "for i in itertools.product(nr_topics_list,min_topic_size_list,hbscan_min_cluster_size_list):\n",
    "    if os.path.exists(f\"../models/BERTopic50Char{i[0].capitalize()}Classes{i[1]}MinTopicSize{i[2]}HbscanMinClusterSize/BERTopicmodel\"):\n",
    "        print('wuhu', i)\n",
    "        continue\n",
    "    BERTopic_Analysis = BERTopicAnalysis(input_file=\"../data/BERTopicInput50CharMin.csv\",\n",
    "                                         k_cluster=i[0],\n",
    "                                         min_topic_size=i[1],\n",
    "                                         hbscan_min_cluster_size=i[2]\n",
    "                                     )\n",
    "    print(i)    \n",
    "    BERTopic_Analysis.run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/BERTopicInput50CharMin.csv\") as file:\n",
    "    lines = file.readlines()\n",
    "    text_to_analyse_list = [line.rstrip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../models/BERTopic_50Char10Classes/pred_on_whole_data_translated_Sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "fp = open(\"test.txt\")\n",
    "data = fp.read()\n",
    "tokenizer.tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    if len(x) >= 500:\n",
    "        for i in tokenize.sent_tokenize(x):\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_counts = df[df.chat.isin(['https://t.me/zh_helps_ukraine', 'https://t.me/zh_helps_UArefugee',\n",
    "       'https://t.me/zurich_hb_help', 'https://t.me/zh_housing',\n",
    "       'https://t.me/Zurich_UA', 'https://t.me/zh_helps_UArefugees', 'https://t.me/Zh_helps_UA_mums', 'https://t.me/job_sw_ukrainians',\n",
    "       'https://t.me/zh_back_ukraine', 'https://t.me/zh_helps_logistics',])].value_counts(['cluster', 'week']).reset_index()\n",
    "df_value_counts.columns = ['cluster', 'week', 'count']\n",
    "mydict = {'no_class':-1,\n",
    "          'medical': 0, \n",
    "          'teaching': 1,\n",
    "          'banking': 2,\n",
    "          'transport_UKR_CH': 3,\n",
    "          'pets': 4,\n",
    "          'immigration': 5,\n",
    "          'transport_train_EU': 6,\n",
    "          'website_links': 7,\n",
    "          'volunteering': 8,\n",
    "          'transport_train_CH': 9}\n",
    "df_value_counts['cluster_names'] = df_value_counts['cluster'].apply(lambda x: list(mydict.keys())[list(mydict.values()).index(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actors = pd.DataFrame(columns=[\"cluster_name\", \"message_sender\", \"nr_post\"])\n",
    "for i in df.cluster_name.unique():\n",
    "    df[df['cluster_name']==i].value_counts('messageSender').iloc[:10]\n",
    "    df_actors_i = df[df['cluster_name']==i].value_counts('messageSender').iloc[:10].reset_index()\n",
    "    df_actors_i[\"cluster_name\"] = i\n",
    "    df_actors_i = df_actors_i[[\"cluster_name\", \"messageSender\", 0]]\n",
    "    df_actors_i.columns = [\"cluster_name\", \"message_sender\", \"nr_post\"]\n",
    "    df_actors = pd.concat([df_actors, df_actors_i], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"../models/BERTopic100CharMin2500CharMax_10ClassesRedo/df.csv\")\n",
    "df['uniqueIdentifier'] = df.apply(lambda x: x[\"chat\"] + \"_\" + str(x[\"messageID\"]), axis=1)\n",
    "df['uniqueIdentifierReply'] = df.apply(lambda x: x[\"chat\"] + \"_\" + str(x[\"messageReplyID\"])[:-2], axis=1)\n",
    "df = df[~df.chat.isin([\"https://t.me/campax_ukraine_help_switzerland\", \"https://t.me/helppetsfromukraine\"])] \n",
    "mydict = {'no_class':-1,\n",
    "          'medical': 0, \n",
    "          'legal_issues': 1,\n",
    "          'travel': 2,\n",
    "          'immigration': 3,\n",
    "          'childcare': 4,\n",
    "          'education': 5,\n",
    "          'veterinarian': 6,\n",
    "          'banking': 7,\n",
    "          'passport_information': 8,\n",
    "          'weblinks': 9}\n",
    "df['cluster_names'] = df['cluster'].apply(lambda x: list(mydict.keys())[list(mydict.values()).index(x)])\n",
    "df['week']=df['messageDatetime'].apply(lambda x: pd.to_datetime(x).isocalendar()[1])\n",
    "df_value_counts = df.groupby(['cluster','week']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# for i in df_value_counts.cluster.unique()[1:]:\n",
    "fig = px.line(df_value_counts[df_value_counts.cluster_names != \"no_class\"].sort_values(['week']), x=\"week\", y=\"count\", color='cluster_names', title='Cluster over time')\n",
    "fig.show()\n",
    "# fig.write_html(\"../models/BERTopic_50Char10Classes/AllGroups.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# for i in df_value_counts.cluster.unique()[1:]:\n",
    "fig = px.line(df_value_counts[df_value_counts.cluster != -1].sort_values(['week']), x=\"week\", y=\"count\", color='cluster_names', title='Cluster over time')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in df_value_counts.cluster.unique()[1:]:\n",
    "    plt.plot(df_value_counts[df_value_counts.cluster == i].sort_values(['week'])['week'], df_value_counts[df_value_counts.cluster == i].sort_values(['week'])['count'], linestyle = 'dotted', label=list(mydict.keys())[list(mydict.values()).index(i)])\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414616, 10)\n",
      "(62153, 10)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../models/BERTopic100CharMin2500CharMax_25/df.csv\")\n",
    "print(df.shape)\n",
    "df = df[df.cluster!=-1]\n",
    "print(df.shape)\n",
    "# df = df[df.messageTextEnglish.apply(type) == str]\n",
    "# print(df.shape)\n",
    "# df = df[df['messageTextEnglish'].notnull()]\n",
    "# print(df.shape)\n",
    "# df[df[\"messageText\"].str.len()<512]\n",
    "# df = df[df['messageTextEnglish'].str.len() <= 513]\n",
    "# df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.6600586771965027}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)\n",
    "sentiment_task(\"T'estimo!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::cumsum.out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universität Zürich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y113sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m text \u001b[39m=\u001b[39m preprocess(text)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y113sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m encoded_input \u001b[39m=\u001b[39m tokenizer(text, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y113sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mencoded_input)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y113sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m scores \u001b[39m=\u001b[39m output[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y113sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m scores \u001b[39m=\u001b[39m softmax(scores)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1218\u001b[0m, in \u001b[0;36mXLMRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1210\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1218\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[1;32m   1219\u001b[0m     input_ids,\n\u001b[1;32m   1220\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1221\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1222\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1223\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1224\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1225\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1226\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1227\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1228\u001b[0m )\n\u001b[1;32m   1229\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1230\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:841\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    839\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 841\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m    842\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    843\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    844\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m    845\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    846\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[1;32m    847\u001b[0m )\n\u001b[1;32m    848\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m    849\u001b[0m     embedding_output,\n\u001b[1;32m    850\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    858\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m    859\u001b[0m )\n\u001b[1;32m    860\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:102\u001b[0m, in \u001b[0;36mXLMRobertaEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m position_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m         \u001b[39m# Create the position ids from the input token ids. Any padded tokens remain padded.\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m         position_ids \u001b[39m=\u001b[39m create_position_ids_from_input_ids(input_ids, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, past_key_values_length)\n\u001b[1;32m    103\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m         position_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_position_ids_from_inputs_embeds(inputs_embeds)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1593\u001b[0m, in \u001b[0;36mcreate_position_ids_from_input_ids\u001b[0;34m(input_ids, padding_idx, past_key_values_length)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[39m# The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m mask \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mne(padding_idx)\u001b[39m.\u001b[39mint()\n\u001b[0;32m-> 1593\u001b[0m incremental_indices \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39;49mcumsum(mask, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mtype_as(mask) \u001b[39m+\u001b[39m past_key_values_length) \u001b[39m*\u001b[39m mask\n\u001b[1;32m   1594\u001b[0m \u001b[39mreturn\u001b[39;00m incremental_indices\u001b[39m.\u001b[39mlong() \u001b[39m+\u001b[39m padding_idx\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::cumsum.out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)#.to(\"mps\")\n",
    "model.to(\"mps\")\n",
    "text = \"Good night 😊\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt').to(\"mps\")\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "\n",
    "# text = \"Good night 😊\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "\n",
    "# Print labels and scores\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good night 😊'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")#.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "def analyse_sentiment(x):\n",
    "    if len(x)>512:\n",
    "        x_split_list = []\n",
    "        n = 400\n",
    "        for i in range(0, len(x), n):\n",
    "            x_split_list.append(x[i:i+n])\n",
    "        scores_split_list = []    \n",
    "        for x_split in x_split_list:\n",
    "            encoded_tweet = tokenizer(x_split, return_tensors='pt')#.to(\"mps\")\n",
    "            output = model(**encoded_tweet)\n",
    "            scores_split = output[0][0].detach().numpy()\n",
    "            scores_split = softmax(scores_split)\n",
    "            scores_split_list.append(scores_split)\n",
    "        return np.mean(np.array(scores_split_list), axis=0)\n",
    "        \n",
    "    else:\n",
    "        encoded_tweet = tokenizer(x, return_tensors='pt')#.to(\"mps\")\n",
    "        output = model(**encoded_tweet)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        return scores\n",
    "        \n",
    "def scores_to_sentiment(x):\n",
    "    max_value = max(x.tolist())\n",
    "    max_index = x.tolist().index(max_value)\n",
    "    return labels[max_index] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10218946"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[df.cluster!=-1].messageText.str.len())\n",
    "10218946\n",
    " 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"👋Вітаємо на каналі КОРИСНО (HELPFUL) Швейцарського Червоного Хреста. Ми — група волонтерів, яка допоможе вам знайти відповіді на ваші запитання. Ми намагаємось відповідати впродовж 24 годин. Відповіді на запитання надаються з понеділка по п’ятницю. Перш ніж поставити своє запитання, просимо вас спочатку переглянути веб-сайт КОРИСНО (HELPFUL): helpful.redcross.ch На цьому каналі можна використовувати українську, російську, англійську та державні мови Швейцарії. Ми відповідатимемо здебільшого державними мовами Швейцарії та пропонуватимемо перекласти наші відповіді. Для цього скористайтеся функцією «перекладу», яку пропонує Telegram. Указівки та коментарі наведено нижче. ⚠️Оскільки це публічний канал, ваші коментарі бачитимуть всі бажаючі. Якщо у вас є запитання, що передбачає розкриття особистої інформації, просимо вас додати в коментарі значок ✉️. Тоді ми надішлемо вам приватне повідомлення в зашифрованому чаті. 📍Відповіді на деякі питання були надані в приватних повідомленнях. Просимо вас писати під відповідними секціями в основному каналі. ____ 👋Добро пожаловать на канал HELPFUL Швейцарского Красного Креста. Мы - команда волонтеров и готовы помочь вам найти ответы на ваши вопросы. Мы стараемся давать ответы в течение 24 часов. Мы будем отвечать на ваши вопросы с понедельника по пятницу. Прежде чем задать свой вопрос, просим вас сначала заглянуть на сайт HELPFUL: helpful.redcross.ch. На этом канале используются украинский, русский, английский или швейцарские государственные языки. Мы будем отвечать преимущественно на языках, используемых в Швейцарии, и просим вас переводить наши ответы. Для этого воспользуйтесь опцией \"\"перевести\"\", имеющейся в Telegram. Смотрите инструкции в комментариях ниже. ⚠️Поскольку этот канал является публичным, ваши комментарии сможет увидеть каждый. Если у вас есть вопрос, подразумевающий предоставления каких-то личных данных, просим вас отправить значок ✉️ в комментарии. После этого мы отправим вам личное сообщение в защищенном чате. ___ 👋 Welcome to the channel HELPFUL by the Swiss Red Cross. We are a team of volunteers and will help you find answers to your questions. We aim to respond within 24 hours. The questions will be answered from Monday to Friday. Before asking your question, we ask you to please first check the HELPFUL website: helpful.redcross.ch The languages used in this channel are Ukrainian, Russian, English or the Swiss national languages. We will mainly answer using the Swiss national languages and ask you to translate our answers. To do this please use the option “translate” provided by Telegram. See instructions in the comments below. ⚠️ As this channel is public, your comments will be seen by everyone. If you have a question that requires sharing some personal data, we ask you to send the icon ✉️ in the comment. We will then send you a private message in a secured chat. 📍Some answers are provided in private messages. We also please ask you to write under the appropriate sections in the main channel.\"\n",
    "x1 = \"Dear group members, We are pleased to announce that the **second part of the HELPFUL website** about staying in Switzerland is already online 🎉 Please check out the published information on popular topics such as: work, education, finding accommodation and language learning here ➡️ https://helpful.redcross.ch/uk/perebuvannya We hope that you will find a lot of useful information for yourself and if you have any questions, we are ready to answer them. Have a nice day! Sincerely, HELPFUL Team\"\n",
    "x_split1 = analyse_sentiment(df.messageText[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_to_sentiment(x_split1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12221589, 0.8199387 , 0.05784534], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08510411, 0.78612053, 0.1287754 ], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(x_split), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 565])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_split[\"input_ids\"].shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['👋Вітаємо на каналі КОРИСНО (HELPFUL) Швейцарського Червоного Хреста. Ми — група волонтерів, яка допоможе вам знайти відповіді на ваші запитання. Ми намагаємось відповідати впродовж 24 годин. Відповіді на запитання надаються з понеділка по п’ятницю. Перш ніж поставити своє запитання, просимо вас спочатку переглянути веб-сайт КОРИСНО (HELPFUL): helpful.redcross.ch На цьому каналі можна використовувати українську, російську, англійську та державні мови Швейцарії. Ми відповідатимемо здебільшого державними мовам', 'и Швейцарії та пропонуватимемо перекласти наші відповіді. Для цього скористайтеся функцією «перекладу», яку пропонує Telegram. Указівки та коментарі наведено нижче. ⚠️Оскільки це публічний канал, ваші коментарі бачитимуть всі бажаючі. Якщо у вас є запитання, що передбачає розкриття особистої інформації, просимо вас додати в коментарі значок ✉️. Тоді ми надішлемо вам приватне повідомлення в зашифрованому чаті. 📍Відповіді на деякі питання були надані в приватних повідомленнях. Просимо вас писати під відповідн', 'ими секціями в основному каналі. ____ 👋Добро пожаловать на канал HELPFUL Швейцарского Красного Креста. Мы - команда волонтеров и готовы помочь вам найти ответы на ваши вопросы. Мы стараемся давать ответы в течение 24 часов. Мы будем отвечать на ваши вопросы с понедельника по пятницу. Прежде чем задать свой вопрос, просим вас сначала заглянуть на сайт HELPFUL: helpful.redcross.ch. На этом канале используются украинский, русский, английский или швейцарские государственные языки. Мы будем отвечать преимуществе', 'нно на языках, используемых в Швейцарии, и просим вас переводить наши ответы. Для этого воспользуйтесь опцией перевести, имеющейся в Telegram. Смотрите инструкции в комментариях ниже. ⚠️Поскольку этот канал является публичным, ваши комментарии сможет увидеть каждый. Если у вас есть вопрос, подразумевающий предоставления каких-то личных данных, просим вас отправить значок ✉️ в комментарии. После этого мы отправим вам личное сообщение в защищенном чате. ___ 👋 Welcome to the channel HELPFUL by the Swiss Red Cr', 'oss. We are a team of volunteers and will help you find answers to your questions. We aim to respond within 24 hours. The questions will be answered from Monday to Friday. Before asking your question, we ask you to please first check the HELPFUL website: helpful.redcross.ch The languages used in this channel are Ukrainian, Russian, English or the Swiss national languages. We will mainly answer using the Swiss national languages and ask you to translate our answers. To do this please use the option “translat', 'e” provided by Telegram. See instructions in the comments below. ⚠️ As this channel is public, your comments will be seen by everyone. If you have a question that requires sharing some personal data, we ask you to send the icon ✉️ in the comment. We will then send you a private message in a secured chat. 📍Some answers are provided in private messages. We also please ask you to write under the appropriate sections in the main channel.']\n"
     ]
    }
   ],
   "source": [
    "x = \"👋Вітаємо на каналі КОРИСНО (HELPFUL) Швейцарського Червоного Хреста. Ми — група волонтерів, яка допоможе вам знайти відповіді на ваші запитання. Ми намагаємось відповідати впродовж 24 годин. Відповіді на запитання надаються з понеділка по п’ятницю. Перш ніж поставити своє запитання, просимо вас спочатку переглянути веб-сайт КОРИСНО (HELPFUL): helpful.redcross.ch На цьому каналі можна використовувати українську, російську, англійську та державні мови Швейцарії. Ми відповідатимемо здебільшого державними мовами Швейцарії та пропонуватимемо перекласти наші відповіді. Для цього скористайтеся функцією «перекладу», яку пропонує Telegram. Указівки та коментарі наведено нижче. ⚠️Оскільки це публічний канал, ваші коментарі бачитимуть всі бажаючі. Якщо у вас є запитання, що передбачає розкриття особистої інформації, просимо вас додати в коментарі значок ✉️. Тоді ми надішлемо вам приватне повідомлення в зашифрованому чаті. 📍Відповіді на деякі питання були надані в приватних повідомленнях. Просимо вас писати під відповідними секціями в основному каналі. ____ 👋Добро пожаловать на канал HELPFUL Швейцарского Красного Креста. Мы - команда волонтеров и готовы помочь вам найти ответы на ваши вопросы. Мы стараемся давать ответы в течение 24 часов. Мы будем отвечать на ваши вопросы с понедельника по пятницу. Прежде чем задать свой вопрос, просим вас сначала заглянуть на сайт HELPFUL: helpful.redcross.ch. На этом канале используются украинский, русский, английский или швейцарские государственные языки. Мы будем отвечать преимущественно на языках, используемых в Швейцарии, и просим вас переводить наши ответы. Для этого воспользуйтесь опцией \"\"перевести\"\", имеющейся в Telegram. Смотрите инструкции в комментариях ниже. ⚠️Поскольку этот канал является публичным, ваши комментарии сможет увидеть каждый. Если у вас есть вопрос, подразумевающий предоставления каких-то личных данных, просим вас отправить значок ✉️ в комментарии. После этого мы отправим вам личное сообщение в защищенном чате. ___ 👋 Welcome to the channel HELPFUL by the Swiss Red Cross. We are a team of volunteers and will help you find answers to your questions. We aim to respond within 24 hours. The questions will be answered from Monday to Friday. Before asking your question, we ask you to please first check the HELPFUL website: helpful.redcross.ch The languages used in this channel are Ukrainian, Russian, English or the Swiss national languages. We will mainly answer using the Swiss national languages and ask you to translate our answers. To do this please use the option “translate” provided by Telegram. See instructions in the comments below. ⚠️ As this channel is public, your comments will be seen by everyone. If you have a question that requires sharing some personal data, we ask you to send the icon ✉️ in the comment. We will then send you a private message in a secured chat. 📍Some answers are provided in private messages. We also please ask you to write under the appropriate sections in the main channel.\"\n",
    "\n",
    "my_list = []\n",
    "\n",
    "n = 512\n",
    "\n",
    "for i in range(0, len(x), n):\n",
    "    my_list.append(x[i:i+n])\n",
    "\n",
    "print(my_list)  # 👉️ ['ab', 'cd', 'ef', 'gh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/BERTopic100CharMin2500CharMax_20/df'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'models/BERTopic100CharMin2500CharMax_20/df.csv'.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"👋Вітаємо на каналі КОРИСНО (HELPFUL) Швейцарського Червоного Хреста. Ми — група волонтерів, яка допоможе вам знайти відповіді на ваші запитання. Ми намагаємось відповідати впродовж 24 годин. Відповіді на запитання надаються з понеділка по п’ятницю. Перш ніж поставити своє запитання, просимо вас спочатку переглянути веб-сайт КОРИСНО (HELPFUL): helpful.redcross.ch На цьому каналі можна використовувати українську, російську, англійську та державні мови Швейцарії. Ми відповідатимемо здебільшого державними мовами Швейцарії та пропонуватимемо перекласти наші відповіді. Для цього скористайтеся функцією «перекладу», яку пропонує Telegram. Указівки та коментарі наведено нижче. ⚠️Оскільки це публічний канал, ваші коментарі бачитимуть всі бажаючі. Якщо у вас є запитання, що передбачає розкриття особистої інформації, просимо вас додати в коментарі значок ✉️. Тоді ми надішлемо вам приватне повідомлення в зашифрованому чаті. 📍Відповіді на деякі питання були надані в приватних повідомленнях. Просимо вас писати під відповідними секціями в основному каналі. ____ 👋Добро пожаловать на канал HELPFUL Швейцарского Красного Креста. Мы - команда волонтеров и готовы помочь вам найти ответы на ваши вопросы. Мы стараемся давать ответы в течение 24 часов. Мы будем отвечать на ваши вопросы с понедельника по пятницу. Прежде чем задать свой вопрос, просим вас сначала заглянуть на сайт HELPFUL: helpful.redcross.ch. На этом канале используются украинский, русский, английский или швейцарские государственные языки. Мы будем отвечать преимущественно на языках, используемых в Швейцарии, и просим вас переводить наши ответы. Для этого воспользуйтесь опцией \"\"перевести\"\", имеющейся в Telegram. Смотрите инструкции в комментариях ниже. ⚠️Поскольку этот канал является публичным, ваши комментарии сможет увидеть каждый. Если у вас есть вопрос, подразумевающий предоставления каких-то личных данных, просим вас отправить значок ✉️ в комментарии. После этого мы отправим вам личное сообщение в защищенном чате. ___ 👋 Welcome to the channel HELPFUL by the Swiss Red Cross. We are a team of volunteers and will help you find answers to your questions. We aim to respond within 24 hours. The questions will be answered from Monday to Friday. Before asking your question, we ask you to please first check the HELPFUL website: helpful.redcross.ch The languages used in this channel are Ukrainian, Russian, English or the Swiss national languages. We will mainly answer using the Swiss national languages and ask you to translate our answers. To do this please use the option “translate” provided by Telegram. See instructions in the comments below. ⚠️ As this channel is public, your comments will be seen by everyone. If you have a question that requires sharing some personal data, we ask you to send the icon ✉️ in the comment. We will then send you a private message in a secured chat. 📍Some answers are provided in private messages. We also please ask you to write under the appropriate sections in the main channel.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414616/414616 [00:00<00:00, 1092111.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df['sentiment'] = df['messageText'].progress_apply(lambda x: analyse_sentiment(x))\n",
    "df['sentiment_name'] = df['sentiment'].progress_apply(lambda x: scores_to_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test= df_test.sort_values(\"sentiment_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "sentiment_name=Negative<br>cluster_name=%{x}<br>percentage=%{y}<extra></extra>",
         "legendgroup": "Negative",
         "marker": {
          "color": "red",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Negative",
         "offsetgroup": "Negative",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "transport_UKR_CH",
          "volunteering",
          "transport_train_EU",
          "transport_train_CH",
          "immigration",
          "medical",
          "teaching",
          "banking",
          "pets",
          "website_links"
         ],
         "xaxis": "x",
         "y": [
          0.032595573440643864,
          0.07445805843543826,
          0.0882816605359958,
          0.10039481105470953,
          0.15559655596555966,
          0.22366602156483273,
          0.09029411764705883,
          0.10580847723704867,
          0.18043087971274685,
          0.05168986083499006
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "sentiment_name=Neutral<br>cluster_name=%{x}<br>percentage=%{y}<extra></extra>",
         "legendgroup": "Neutral",
         "marker": {
          "color": "blue",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Neutral",
         "offsetgroup": "Neutral",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "medical",
          "banking",
          "transport_train_CH",
          "transport_train_EU",
          "pets",
          "teaching",
          "volunteering",
          "transport_UKR_CH",
          "immigration",
          "website_links"
         ],
         "xaxis": "x",
         "y": [
          0.7005805916505391,
          0.8091051805337519,
          0.7794698251551043,
          0.7714135575407252,
          0.6723518850987432,
          0.5882352941176471,
          0.7290292177191329,
          0.7352112676056338,
          0.7718327183271833,
          0.856858846918489
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "sentiment_name=Positive<br>cluster_name=%{x}<br>percentage=%{y}<extra></extra>",
         "legendgroup": "Positive",
         "marker": {
          "color": "green",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Positive",
         "offsetgroup": "Positive",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "teaching",
          "immigration",
          "website_links",
          "transport_train_EU",
          "banking",
          "pets",
          "medical",
          "transport_UKR_CH",
          "transport_train_CH",
          "volunteering"
         ],
         "xaxis": "x",
         "y": [
          0.3214705882352941,
          0.07257072570725707,
          0.09145129224652088,
          0.14030478192327903,
          0.08508634222919938,
          0.14721723518850988,
          0.07575338678462815,
          0.23219315895372233,
          0.12013536379018612,
          0.19651272384542884
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "sentiment_name"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Sentiment within cluster"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "cluster_name"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "percentage"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "long_df = px.data.medals_long()\n",
    "\n",
    "fig = px.bar(df_test, x=\"cluster_name\", y='percentage', color=\"sentiment_name\", title=\"Sentiment within cluster\", color_discrete_map={'Negative':'red', 'Neutral':'blue', 'Positive':'green'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "long_df = px.data.medals_long()\n",
    "\n",
    "fig = px.bar(df_test, x=\"cluster_name\", y=\"percentage\", color=\"sentiment_name\", title=\"Sentiment within cluster\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.cluster.unique():\n",
    "    print(i)\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(df[df.cluster==i].value_counts('sentiment_name').values, labels=df[df.cluster==i].value_counts('sentiment_name').index, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    title = list(mydict.keys())[list(mydict.values()).index(i)]\n",
    "    fig1.suptitle(title, fontsize=12)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "long_df = px.data.medals_long()\n",
    "\n",
    "fig = px.bar(long_df, x=\"nation\", y=\"count\", color=\"medal\", title=\"Long-Form Input\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/kiliansprenkamp/Desktop/OneDrive - Universität Zürich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/models/BERTopic_50Char10Classes/pred_on_whole_data_translated_sentiment_network.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.messageText.str.len().nlargest(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear members of the group, We are glad to announce that **the second part of the HELPFUL website** about staying in Switzerland is already online  Please view the published information on popular topics such as: work, education, housing search and language study here  https://helpful.redcross.ch/uk/perebuvannya Hope you find yourself useful!'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformer for slavic to english\n",
    "\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "import torch\n",
    "\n",
    "# src = \"uk\"  # source language\n",
    "# trg = \"en\"  # target language\n",
    "\n",
    "model_name = f\"Helsinki-NLP/opus-mt-tc-big-zle-en\"\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# tokenizer.to(\"mps\")\n",
    "\n",
    "# model.to(torch.device(\"mps\"))\n",
    "sample_text =  df.messageText[0]\n",
    "batch = tokenizer([sample_text], return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(**batch)\n",
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/62153 [05:46<186:43:27, 10.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universität Zürich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y134sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mmessageTextEnglish\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mmessageText\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mprogress_apply(\u001b[39mlambda\u001b[39;49;00m x: tokenizer\u001b[39m.\u001b[39;49mbatch_decode(model\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtokenizer([x], return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)), skip_special_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/tqdm/std.py:814\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    815\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    816\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/tqdm/std.py:809\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    804\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    805\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    807\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 809\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universität Zürich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 45\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y134sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mmessageTextEnglish\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mmessageText\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: tokenizer\u001b[39m.\u001b[39mbatch_decode(model\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtokenizer([x], return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)), skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:1577\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1574\u001b[0m         input_ids, expand_size\u001b[39m=\u001b[39mnum_beams, is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs\n\u001b[1;32m   1575\u001b[0m     )\n\u001b[1;32m   1576\u001b[0m     \u001b[39m# 12. run beam search\u001b[39;00m\n\u001b[0;32m-> 1577\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[1;32m   1578\u001b[0m         input_ids,\n\u001b[1;32m   1579\u001b[0m         beam_scorer,\n\u001b[1;32m   1580\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1581\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1582\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1583\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1584\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   1585\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1586\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1587\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1588\u001b[0m     )\n\u001b[1;32m   1590\u001b[0m \u001b[39melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   1591\u001b[0m     \u001b[39m# 10. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1593\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m   1594\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         renormalize_logits\u001b[39m=\u001b[39mrenormalize_logits,\n\u001b[1;32m   1599\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:2747\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2743\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   2745\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 2747\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2748\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2749\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2750\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2751\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2752\u001b[0m )\n\u001b[1;32m   2754\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2755\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:1457\u001b[0m, in \u001b[0;36mMarianMTModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1437\u001b[0m             labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1438\u001b[0m         )\n\u001b[1;32m   1440\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\n\u001b[1;32m   1441\u001b[0m     input_ids,\n\u001b[1;32m   1442\u001b[0m     attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1456\u001b[0m )\n\u001b[0;32m-> 1457\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlm_head(outputs[\u001b[39m0\u001b[39;49m]) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_logits_bias\n\u001b[1;32m   1459\u001b[0m masked_lm_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1460\u001b[0m \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['messageTextEnglish'] = df['messageText'].progress_apply(lambda x: tokenizer.batch_decode(model.generate(**tokenizer([x], return_tensors=\"pt\")), skip_special_tokens=True)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::remainder.Tensor_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universität Zürich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y131sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pipe \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHelsinki-NLP/opus-mt-tc-big-zle-en\u001b[39m\u001b[39m\"\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y131sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(pipe(\u001b[39m\"\u001b[39;49m\u001b[39mСкільки мені слід купити пива?\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:351\u001b[0m, in \u001b[0;36mTranslationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    322\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39m    Translate the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39m          token ids of the translation.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:150\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    152\u001b[0m         \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m)\n\u001b[1;32m    153\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(el, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m args[\u001b[39m0\u001b[39m])\n\u001b[1;32m    154\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result)\n\u001b[1;32m    155\u001b[0m     ):\n\u001b[1;32m    156\u001b[0m         \u001b[39mreturn\u001b[39;00m [res[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:1074\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1073\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1074\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:1081\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1080\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1081\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1082\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1083\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:990\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m    989\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 990\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m    991\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    992\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:172\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generate_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_length)\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m], generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 172\u001b[0m output_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[1;32m    173\u001b[0m out_b \u001b[39m=\u001b[39m output_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:1577\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1574\u001b[0m         input_ids, expand_size\u001b[39m=\u001b[39mnum_beams, is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs\n\u001b[1;32m   1575\u001b[0m     )\n\u001b[1;32m   1576\u001b[0m     \u001b[39m# 12. run beam search\u001b[39;00m\n\u001b[0;32m-> 1577\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[1;32m   1578\u001b[0m         input_ids,\n\u001b[1;32m   1579\u001b[0m         beam_scorer,\n\u001b[1;32m   1580\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1581\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1582\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1583\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1584\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   1585\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1586\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1587\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1588\u001b[0m     )\n\u001b[1;32m   1590\u001b[0m \u001b[39melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   1591\u001b[0m     \u001b[39m# 10. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1593\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m   1594\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         renormalize_logits\u001b[39m=\u001b[39mrenormalize_logits,\n\u001b[1;32m   1599\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:2797\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2792\u001b[0m next_token_scores, next_tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(\n\u001b[1;32m   2793\u001b[0m     next_token_scores, \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m num_beams, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, largest\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39msorted\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2794\u001b[0m )\n\u001b[1;32m   2796\u001b[0m next_indices \u001b[39m=\u001b[39m torch_int_div(next_tokens, vocab_size)\n\u001b[0;32m-> 2797\u001b[0m next_tokens \u001b[39m=\u001b[39m next_tokens \u001b[39m%\u001b[39;49m vocab_size\n\u001b[1;32m   2799\u001b[0m \u001b[39m# stateless\u001b[39;00m\n\u001b[1;32m   2800\u001b[0m beam_outputs \u001b[39m=\u001b[39m beam_scorer\u001b[39m.\u001b[39mprocess(\n\u001b[1;32m   2801\u001b[0m     input_ids,\n\u001b[1;32m   2802\u001b[0m     next_token_scores,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2807\u001b[0m     beam_indices\u001b[39m=\u001b[39mbeam_indices,\n\u001b[1;32m   2808\u001b[0m )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::remainder.Tensor_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-tc-big-zle-en\", device=\"mps\")\n",
    "print(pipe(\"Скільки мені слід купити пива?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/414616 [00:25<196:40:47,  1.71s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universität Zürich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y132sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mmessageTextEnglish\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mmessageText\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mprogress_apply(\u001b[39mlambda\u001b[39;49;00m x: pipe(x, max_length\u001b[39m=\u001b[39;49m\u001b[39m2500\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/tqdm/std.py:814\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    815\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    816\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/tqdm/std.py:809\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    804\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    805\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    807\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 809\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universität Zürich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 45\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#Y132sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mmessageTextEnglish\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mmessageText\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m x: pipe(x, max_length\u001b[39m=\u001b[39;49m\u001b[39m2500\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:351\u001b[0m, in \u001b[0;36mTranslationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    322\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39m    Translate the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39m          token ids of the translation.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:150\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    152\u001b[0m         \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m)\n\u001b[1;32m    153\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(el, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m args[\u001b[39m0\u001b[39m])\n\u001b[1;32m    154\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result)\n\u001b[1;32m    155\u001b[0m     ):\n\u001b[1;32m    156\u001b[0m         \u001b[39mreturn\u001b[39;00m [res[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:1074\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1073\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1074\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:1081\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1080\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1081\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1082\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1083\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/base.py:990\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m    989\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 990\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m    991\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    992\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:172\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generate_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_length)\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m], generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 172\u001b[0m output_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[1;32m    173\u001b[0m out_b \u001b[39m=\u001b[39m output_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:1577\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1574\u001b[0m         input_ids, expand_size\u001b[39m=\u001b[39mnum_beams, is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs\n\u001b[1;32m   1575\u001b[0m     )\n\u001b[1;32m   1576\u001b[0m     \u001b[39m# 12. run beam search\u001b[39;00m\n\u001b[0;32m-> 1577\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[1;32m   1578\u001b[0m         input_ids,\n\u001b[1;32m   1579\u001b[0m         beam_scorer,\n\u001b[1;32m   1580\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1581\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1582\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1583\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1584\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   1585\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1586\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1587\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1588\u001b[0m     )\n\u001b[1;32m   1590\u001b[0m \u001b[39melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   1591\u001b[0m     \u001b[39m# 10. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1593\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m   1594\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         renormalize_logits\u001b[39m=\u001b[39mrenormalize_logits,\n\u001b[1;32m   1599\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/generation_utils.py:2747\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2743\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   2745\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 2747\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2748\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2749\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2750\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2751\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2752\u001b[0m )\n\u001b[1;32m   2754\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2755\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:1440\u001b[0m, in \u001b[0;36mMarianMTModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1435\u001b[0m     \u001b[39mif\u001b[39;00m decoder_input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decoder_inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1436\u001b[0m         decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1437\u001b[0m             labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1438\u001b[0m         )\n\u001b[0;32m-> 1440\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1441\u001b[0m     input_ids,\n\u001b[1;32m   1442\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1443\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1444\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   1445\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1446\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1447\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1448\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1449\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1450\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1451\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1452\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1453\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1454\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1455\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1456\u001b[0m )\n\u001b[1;32m   1457\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(outputs[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_logits_bias\n\u001b[1;32m   1459\u001b[0m masked_lm_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:1240\u001b[0m, in \u001b[0;36mMarianModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1233\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1234\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1235\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1237\u001b[0m     )\n\u001b[1;32m   1239\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1240\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1241\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1242\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1243\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_outputs[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m   1244\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1245\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1246\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1247\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1248\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1249\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1250\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1251\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1252\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1253\u001b[0m )\n\u001b[1;32m   1255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1256\u001b[0m     \u001b[39mreturn\u001b[39;00m decoder_outputs \u001b[39m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:1042\u001b[0m, in \u001b[0;36mMarianDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m   1031\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m   1032\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1039\u001b[0m     )\n\u001b[1;32m   1040\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1042\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m   1043\u001b[0m         hidden_states,\n\u001b[1;32m   1044\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1045\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1046\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1047\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1048\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49m(\n\u001b[1;32m   1049\u001b[0m             cross_attn_head_mask[idx] \u001b[39mif\u001b[39;49;00m cross_attn_head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   1050\u001b[0m         ),\n\u001b[1;32m   1051\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1052\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1053\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1054\u001b[0m     )\n\u001b[1;32m   1055\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1057\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:424\u001b[0m, in \u001b[0;36mMarianDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    422\u001b[0m self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    425\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    426\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    427\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    428\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    429\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    430\u001b[0m )\n\u001b[1;32m    431\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m    432\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/transformers/models/marian/modeling_marian.py:208\u001b[0m, in \u001b[0;36mMarianAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39melif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39m# reuse k, v, self_attention\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     key_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj(hidden_states), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, bsz)\n\u001b[0;32m--> 208\u001b[0m     value_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj(hidden_states), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, bsz)\n\u001b[1;32m    209\u001b[0m     key_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([past_key_value[\u001b[39m0\u001b[39m], key_states], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    210\u001b[0m     value_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([past_key_value[\u001b[39m1\u001b[39m], value_states], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df[\"messageTextEnglish\"] = df[\"messageText\"].progress_apply(lambda x: pipe(x, max_length=2500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# potential publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../models//BERTopic100CharMin2500CharMax_10ClassesNewestData/df.csv\")\n",
    "df['uniqueIdentifier'] = df.apply(lambda x: x[\"chat\"] + \"_\" + str(x[\"messageID\"]), axis=1)\n",
    "df['uniqueIdentifierReply'] = df.apply(lambda x: x[\"chat\"] + \"_\" + str(x[\"messageReplyID\"])[:-2], axis=1)\n",
    "# df = df[~df.chat.isin([\"https://t.me/campax_ukraine_help_switzerland\", \"https://t.me/helppetsfromukraine\"])] \n",
    "class_name_dict = {'no_class':-1,\n",
    "          'Medical': 0, \n",
    "          'Complaints': 1,\n",
    "          'Asylum/Volunteering': 2,\n",
    "          'Banking': 3,\n",
    "          'Train Travel': 4,\n",
    "          'S Status': 5,\n",
    "          'Accomodation': 6,\n",
    "          'Veterinarian': 7,\n",
    "          'Passport Information': 8,\n",
    "          'Transport UKR CH': 9}\n",
    "df['cluster_names'] = df['cluster'].apply(lambda x: list(class_name_dict.keys())[list(class_name_dict.values()).index(x)])\n",
    "df['week']=df['messageDatetime'].apply(lambda x: pd.to_datetime(x).isocalendar()[1])\n",
    "messages_per_week_dict = dict(df.value_counts(\"week\"))\n",
    "df_value_counts = df.value_counts([\"cluster_names\", \"week\"]).reset_index()\n",
    "df_value_counts.columns = [\"cluster_names\", \"week\", \"occurence_count\"]\n",
    "df_value_counts['occurence_count_norm'] = df_value_counts.apply(lambda x: x.occurence_count/list(messages_per_week_dict.values())[list(messages_per_week_dict.keys()).index(x.week)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "cluster_names=Transport UKR CH<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Transport UKR CH",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Transport UKR CH",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          1,
          36,
          21,
          54,
          58,
          55,
          55,
          68,
          77,
          65,
          67,
          80,
          81,
          70,
          90,
          78,
          79,
          70,
          102,
          101,
          103,
          103,
          91,
          84,
          75,
          74,
          62,
          56,
          72,
          54,
          75,
          55,
          68,
          52,
          59,
          69,
          47,
          21
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Banking<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Banking",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Banking",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          2,
          8,
          21,
          125,
          136,
          127,
          191,
          181,
          127,
          198,
          178,
          90,
          149,
          182,
          143,
          136,
          109,
          179,
          108,
          95,
          109,
          113,
          93,
          65,
          108,
          56,
          36,
          60,
          73,
          67,
          42,
          58,
          73,
          50,
          49,
          29,
          52,
          22
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=S Status<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "S Status",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "S Status",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          2,
          9,
          51,
          254,
          482,
          353,
          309,
          202,
          258,
          197,
          180,
          146,
          161,
          124,
          126,
          141,
          111,
          100,
          123,
          101,
          74,
          93,
          78,
          85,
          64,
          79,
          74,
          60,
          63,
          69,
          40,
          81,
          75,
          55,
          42,
          67,
          38,
          18
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Medical<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Medical",
         "line": {
          "color": "#ab63fa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Medical",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          3,
          24,
          44,
          98,
          238,
          245,
          166,
          187,
          225,
          235,
          182,
          203,
          152,
          172,
          175,
          104,
          178,
          167,
          205,
          171,
          102,
          199,
          83,
          125,
          96,
          97,
          67,
          108,
          139,
          132,
          111,
          131,
          134,
          100,
          143,
          124,
          109,
          63
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Passport Information<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Passport Information",
         "line": {
          "color": "#FFA15A",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Passport Information",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          5,
          13,
          76,
          162,
          230,
          139,
          116,
          80,
          99,
          104,
          85,
          115,
          86,
          114,
          54,
          66,
          75,
          65,
          61,
          60,
          85,
          60,
          81,
          80,
          62,
          58,
          55,
          66,
          54,
          45,
          37,
          58,
          67,
          45,
          34,
          25,
          38,
          11
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Complaints<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Complaints",
         "line": {
          "color": "#19d3f3",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Complaints",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          8,
          66,
          134,
          333,
          476,
          375,
          316,
          234,
          274,
          192,
          277,
          179,
          195,
          143,
          230,
          158,
          137,
          162,
          169,
          151,
          131,
          181,
          177,
          146,
          197,
          195,
          322,
          308,
          208,
          238,
          189,
          209,
          229,
          251,
          262,
          220,
          241,
          78
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Train Travel<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Train Travel",
         "line": {
          "color": "#FF6692",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Train Travel",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          1,
          24,
          92,
          185,
          134,
          109,
          58,
          86,
          97,
          83,
          106,
          111,
          124,
          166,
          208,
          140,
          133,
          161,
          99,
          107,
          59,
          84,
          96,
          100,
          103,
          99,
          54,
          93,
          80,
          70,
          48,
          63,
          53,
          43,
          50,
          60,
          39,
          22
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Asylum/Volunteering<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Asylum/Volunteering",
         "line": {
          "color": "#B6E880",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Asylum/Volunteering",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          66,
          184,
          419,
          360,
          298,
          218,
          183,
          161,
          127,
          147,
          101,
          117,
          74,
          122,
          77,
          71,
          59,
          75,
          70,
          66,
          80,
          71,
          74,
          55,
          54,
          63,
          53,
          45,
          36,
          38,
          40,
          31,
          41,
          47,
          51,
          57,
          25
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Veterinarian<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Veterinarian",
         "line": {
          "color": "#FF97FF",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Veterinarian",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          21,
          64,
          167,
          247,
          239,
          144,
          126,
          153,
          97,
          102,
          104,
          80,
          50,
          60,
          67,
          68,
          56,
          51,
          64,
          41,
          99,
          64,
          47,
          61,
          51,
          42,
          53,
          43,
          21,
          44,
          55,
          51,
          88,
          36,
          44,
          37,
          16
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "cluster_names=Accomodation<br>week=%{x}<br>occurence_count=%{y}<extra></extra>",
         "legendgroup": "Accomodation",
         "line": {
          "color": "#FECB52",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Accomodation",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45
         ],
         "xaxis": "x",
         "y": [
          14,
          60,
          176,
          279,
          232,
          157,
          127,
          145,
          114,
          110,
          88,
          108,
          77,
          74,
          60,
          66,
          68,
          112,
          68,
          62,
          77,
          60,
          57,
          80,
          43,
          61,
          52,
          39,
          50,
          28,
          48,
          45,
          35,
          35,
          44,
          38,
          21
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "cluster_names"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cluster over time"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "week"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "occurence_count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(df_value_counts[df_value_counts.cluster_names != \"no_class\"].sort_values(['week']), x=\"week\", y=\"occurence_count\", color='cluster_names', title='Cluster over time')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df[df.uniqueIdentifier==\"https://t.me/refugeesinSwitzerland_165886\"].messageReactions.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(df.messageReactions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.messageReactions[0]==float('nan'):\n",
    "    print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.search(\"^The.*Spain$\", txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_reaction(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_reaction(reaction):\n",
    "    if isinstance(reaction, str):\n",
    "        m = re.findall('count=(.+?),', reaction)\n",
    "        m = list(map(int, m))\n",
    "        return sum(m)\n",
    "    else:\n",
    "        return float(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reaction_count\"] = df.apply(lambda x: count_reaction(x.messageReactions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>messageSender</th>\n",
       "      <th>messageID</th>\n",
       "      <th>messageReplyID</th>\n",
       "      <th>messageDatetime</th>\n",
       "      <th>messageViews</th>\n",
       "      <th>messageForwards</th>\n",
       "      <th>messageReactions</th>\n",
       "      <th>messageText</th>\n",
       "      <th>cluster</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_5</th>\n",
       "      <th>prob_6</th>\n",
       "      <th>prob_7</th>\n",
       "      <th>prob_8</th>\n",
       "      <th>prob_9</th>\n",
       "      <th>uniqueIdentifier</th>\n",
       "      <th>uniqueIdentifierReply</th>\n",
       "      <th>cluster_names</th>\n",
       "      <th>week</th>\n",
       "      <th>reaction_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland</td>\n",
       "      <td>-1.001507e+12</td>\n",
       "      <td>1465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-09 11:54:20+00:00</td>\n",
       "      <td>349.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Запрошуємо вас на вебінар: ЕНІОСТИЛЬ. Особиста...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.806893e-04</td>\n",
       "      <td>2.828152e-04</td>\n",
       "      <td>8.368974e-06</td>\n",
       "      <td>4.737701e-04</td>\n",
       "      <td>7.745345e-04</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_1465</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland</td>\n",
       "      <td>-1.001507e+12</td>\n",
       "      <td>1464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-08 17:11:10+00:00</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9 листопада, в День української писемності та ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.456777e-73</td>\n",
       "      <td>2.239044e-73</td>\n",
       "      <td>4.911532e-137</td>\n",
       "      <td>2.256454e-73</td>\n",
       "      <td>8.786752e-72</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_1464</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland</td>\n",
       "      <td>-1.001507e+12</td>\n",
       "      <td>1463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-08 16:32:02+00:00</td>\n",
       "      <td>557.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Запрошуємо вас у цьому році на три останніх зу...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.655554e-23</td>\n",
       "      <td>4.205600e-23</td>\n",
       "      <td>3.461776e-24</td>\n",
       "      <td>7.345640e-23</td>\n",
       "      <td>1.251607e-22</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_1463</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland</td>\n",
       "      <td>-1.001507e+12</td>\n",
       "      <td>1462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-08 13:26:26+00:00</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>За півгодини починаємо: Campax запрошує Тебе п...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.784245e-53</td>\n",
       "      <td>4.426106e-53</td>\n",
       "      <td>1.945072e-73</td>\n",
       "      <td>7.376132e-53</td>\n",
       "      <td>1.569924e-18</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_1462</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland</td>\n",
       "      <td>-1.001507e+12</td>\n",
       "      <td>1461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-08 13:25:25+00:00</td>\n",
       "      <td>538.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BCUE сумісно з PwC PricewaterhouseCoopers пров...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295806e-135</td>\n",
       "      <td>5.288591e-71</td>\n",
       "      <td>7.583213e-137</td>\n",
       "      <td>3.823073e-135</td>\n",
       "      <td>7.425516e-57</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_1461</td>\n",
       "      <td>https://t.me/campax_ukraine_help_switzerland_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287958</th>\n",
       "      <td>https://t.me/SwissUA</td>\n",
       "      <td>1.264982e+09</td>\n",
       "      <td>307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-26 18:54:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n",
       "      <td>У нас ще є 6 днів - ми справимось ❤️</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.259132e-170</td>\n",
       "      <td>5.314623e-170</td>\n",
       "      <td>8.549347e-175</td>\n",
       "      <td>7.095355e-170</td>\n",
       "      <td>4.591511e-152</td>\n",
       "      <td>https://t.me/SwissUA_307</td>\n",
       "      <td>https://t.me/SwissUA_n</td>\n",
       "      <td>S Status</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287959</th>\n",
       "      <td>https://t.me/SwissUA</td>\n",
       "      <td>3.368129e+08</td>\n",
       "      <td>306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-26 18:41:02+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n",
       "      <td>если выдает ошибку при подтверждении, подождит...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.113500e-02</td>\n",
       "      <td>1.234151e-02</td>\n",
       "      <td>1.659530e-04</td>\n",
       "      <td>2.000865e-02</td>\n",
       "      <td>2.937823e-02</td>\n",
       "      <td>https://t.me/SwissUA_306</td>\n",
       "      <td>https://t.me/SwissUA_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287960</th>\n",
       "      <td>https://t.me/SwissUA</td>\n",
       "      <td>4.852700e+08</td>\n",
       "      <td>305</td>\n",
       "      <td>301.0</td>\n",
       "      <td>2022-02-26 18:39:36+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Если петиция не открывается, значит очень мног...</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.001051e-129</td>\n",
       "      <td>2.930032e-121</td>\n",
       "      <td>1.000877e-130</td>\n",
       "      <td>8.587486e-129</td>\n",
       "      <td>2.994915e-115</td>\n",
       "      <td>https://t.me/SwissUA_305</td>\n",
       "      <td>https://t.me/SwissUA_301</td>\n",
       "      <td>no_class</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287961</th>\n",
       "      <td>https://t.me/SwissUA</td>\n",
       "      <td>3.368129e+08</td>\n",
       "      <td>304</td>\n",
       "      <td>301.0</td>\n",
       "      <td>2022-02-26 18:09:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n",
       "      <td>спасибо</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.534590e-118</td>\n",
       "      <td>1.942554e-112</td>\n",
       "      <td>1.320957e-121</td>\n",
       "      <td>4.284275e-110</td>\n",
       "      <td>9.667967e-92</td>\n",
       "      <td>https://t.me/SwissUA_304</td>\n",
       "      <td>https://t.me/SwissUA_301</td>\n",
       "      <td>no_class</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287962</th>\n",
       "      <td>https://t.me/SwissUA</td>\n",
       "      <td>4.852700e+08</td>\n",
       "      <td>303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-02-26 18:06:58+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MessageReactions(results=[ReactionCount(reacti...</td>\n",
       "      <td>Ми отримали свіфт, продовжуємо</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.634377e-10</td>\n",
       "      <td>2.199271e-11</td>\n",
       "      <td>6.454256e-16</td>\n",
       "      <td>9.924997e-12</td>\n",
       "      <td>2.202697e-11</td>\n",
       "      <td>https://t.me/SwissUA_303</td>\n",
       "      <td>https://t.me/SwissUA_n</td>\n",
       "      <td>no_class</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287963 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                chat  messageSender  \\\n",
       "0       https://t.me/campax_ukraine_help_switzerland  -1.001507e+12   \n",
       "1       https://t.me/campax_ukraine_help_switzerland  -1.001507e+12   \n",
       "2       https://t.me/campax_ukraine_help_switzerland  -1.001507e+12   \n",
       "3       https://t.me/campax_ukraine_help_switzerland  -1.001507e+12   \n",
       "4       https://t.me/campax_ukraine_help_switzerland  -1.001507e+12   \n",
       "...                                              ...            ...   \n",
       "287958                          https://t.me/SwissUA   1.264982e+09   \n",
       "287959                          https://t.me/SwissUA   3.368129e+08   \n",
       "287960                          https://t.me/SwissUA   4.852700e+08   \n",
       "287961                          https://t.me/SwissUA   3.368129e+08   \n",
       "287962                          https://t.me/SwissUA   4.852700e+08   \n",
       "\n",
       "        messageID  messageReplyID            messageDatetime  messageViews  \\\n",
       "0            1465             NaN  2022-11-09 11:54:20+00:00         349.0   \n",
       "1            1464             NaN  2022-11-08 17:11:10+00:00         600.0   \n",
       "2            1463             NaN  2022-11-08 16:32:02+00:00         557.0   \n",
       "3            1462             NaN  2022-11-08 13:26:26+00:00         561.0   \n",
       "4            1461             NaN  2022-11-08 13:25:25+00:00         538.0   \n",
       "...           ...             ...                        ...           ...   \n",
       "287958        307             NaN  2022-02-26 18:54:00+00:00           NaN   \n",
       "287959        306             NaN  2022-02-26 18:41:02+00:00           NaN   \n",
       "287960        305           301.0  2022-02-26 18:39:36+00:00           NaN   \n",
       "287961        304           301.0  2022-02-26 18:09:06+00:00           NaN   \n",
       "287962        303             NaN  2022-02-26 18:06:58+00:00           NaN   \n",
       "\n",
       "        messageForwards                                   messageReactions  \\\n",
       "0                   0.0                                                NaN   \n",
       "1                   3.0                                                NaN   \n",
       "2                   3.0                                                NaN   \n",
       "3                   0.0                                                NaN   \n",
       "4                   8.0                                                NaN   \n",
       "...                 ...                                                ...   \n",
       "287958              NaN  MessageReactions(results=[ReactionCount(reacti...   \n",
       "287959              NaN  MessageReactions(results=[ReactionCount(reacti...   \n",
       "287960              NaN                                                NaN   \n",
       "287961              NaN  MessageReactions(results=[ReactionCount(reacti...   \n",
       "287962              NaN  MessageReactions(results=[ReactionCount(reacti...   \n",
       "\n",
       "                                              messageText  cluster  ...  \\\n",
       "0       Запрошуємо вас на вебінар: ЕНІОСТИЛЬ. Особиста...       -1  ...   \n",
       "1       9 листопада, в День української писемності та ...       -1  ...   \n",
       "2       Запрошуємо вас у цьому році на три останніх зу...       -1  ...   \n",
       "3       За півгодини починаємо: Campax запрошує Тебе п...       -1  ...   \n",
       "4       BCUE сумісно з PwC PricewaterhouseCoopers пров...       -1  ...   \n",
       "...                                                   ...      ...  ...   \n",
       "287958               У нас ще є 6 днів - ми справимось ❤️        5  ...   \n",
       "287959  если выдает ошибку при подтверждении, подождит...       -1  ...   \n",
       "287960  Если петиция не открывается, значит очень мног...       -1  ...   \n",
       "287961                                            спасибо       -1  ...   \n",
       "287962                     Ми отримали свіфт, продовжуємо       -1  ...   \n",
       "\n",
       "               prob_5         prob_6         prob_7         prob_8  \\\n",
       "0        1.806893e-04   2.828152e-04   8.368974e-06   4.737701e-04   \n",
       "1        4.456777e-73   2.239044e-73  4.911532e-137   2.256454e-73   \n",
       "2        2.655554e-23   4.205600e-23   3.461776e-24   7.345640e-23   \n",
       "3        2.784245e-53   4.426106e-53   1.945072e-73   7.376132e-53   \n",
       "4       1.295806e-135   5.288591e-71  7.583213e-137  3.823073e-135   \n",
       "...               ...            ...            ...            ...   \n",
       "287958  4.259132e-170  5.314623e-170  8.549347e-175  7.095355e-170   \n",
       "287959   1.113500e-02   1.234151e-02   1.659530e-04   2.000865e-02   \n",
       "287960  3.001051e-129  2.930032e-121  1.000877e-130  8.587486e-129   \n",
       "287961  1.534590e-118  1.942554e-112  1.320957e-121  4.284275e-110   \n",
       "287962   7.634377e-10   2.199271e-11   6.454256e-16   9.924997e-12   \n",
       "\n",
       "               prob_9                                   uniqueIdentifier  \\\n",
       "0        7.745345e-04  https://t.me/campax_ukraine_help_switzerland_1465   \n",
       "1        8.786752e-72  https://t.me/campax_ukraine_help_switzerland_1464   \n",
       "2        1.251607e-22  https://t.me/campax_ukraine_help_switzerland_1463   \n",
       "3        1.569924e-18  https://t.me/campax_ukraine_help_switzerland_1462   \n",
       "4        7.425516e-57  https://t.me/campax_ukraine_help_switzerland_1461   \n",
       "...               ...                                                ...   \n",
       "287958  4.591511e-152                           https://t.me/SwissUA_307   \n",
       "287959   2.937823e-02                           https://t.me/SwissUA_306   \n",
       "287960  2.994915e-115                           https://t.me/SwissUA_305   \n",
       "287961   9.667967e-92                           https://t.me/SwissUA_304   \n",
       "287962   2.202697e-11                           https://t.me/SwissUA_303   \n",
       "\n",
       "                                 uniqueIdentifierReply  cluster_names  week  \\\n",
       "0       https://t.me/campax_ukraine_help_switzerland_n       no_class    45   \n",
       "1       https://t.me/campax_ukraine_help_switzerland_n       no_class    45   \n",
       "2       https://t.me/campax_ukraine_help_switzerland_n       no_class    45   \n",
       "3       https://t.me/campax_ukraine_help_switzerland_n       no_class    45   \n",
       "4       https://t.me/campax_ukraine_help_switzerland_n       no_class    45   \n",
       "...                                                ...            ...   ...   \n",
       "287958                          https://t.me/SwissUA_n       S Status     8   \n",
       "287959                          https://t.me/SwissUA_n       no_class     8   \n",
       "287960                        https://t.me/SwissUA_301       no_class     8   \n",
       "287961                        https://t.me/SwissUA_301       no_class     8   \n",
       "287962                          https://t.me/SwissUA_n       no_class     8   \n",
       "\n",
       "        reaction_count  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "...                ...  \n",
       "287958             1.0  \n",
       "287959             1.0  \n",
       "287960             0.0  \n",
       "287961             1.0  \n",
       "287962             1.0  \n",
       "\n",
       "[287963 rows x 25 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.comparis.ch/ 12 Tips як арендувати житло від Comparis: https://www.comparis.ch/immobilien/wohnungssuche/wohnungssuche-tipps-tricks',\n",
       " 'Сайт пошуку аренди житла: https://www.homegate.ch/de',\n",
       " 'Помічниця по господарству з проживанням+допомога з дитиною по необхідності ( 4 роки, спокійний, 4 рази в тиждень відвідує дитячий садок). Надається окрема кімната з санвузлом, харчування, допомога з оформленням статусу S. Або ж приходящу помічницю декілька раз на тиждень. Локація - Adliswil 8134. Деталі в ПП будь-ласка https://www.facebook.com/olya.olga.167',\n",
       " 'Помічниця по господарству з проживанням+допомога з дитиною по необхідності ( 4 роки, спокійний, 4 рази в тиждень відвідує дитячий садок). Надається окрема кімната з санвузлом, харчування, допомога з оформленням статусу S. Або ж приходящу помічницю декілька раз на тиждень. Локація - Adliswil 8134. Деталі в ПП будь-ласка https://www.facebook.com/olya.olga.167',\n",
       " '**Ищете квартиру? Хотите отдельное жильё? Как снять его в разумные сроки? **Эти вопросы обсудили на прошлой неделе на встречах в Берне. Спасибо Elisabeth и Ольге! Разобрали: 1. Шаги аренды кв в CH* 2. Сайты объяв об аренде кв 3. Виды арендодателей 4. Объява о кв: что важно 5. 1-й отклик на объявление 6. Просмотр кв: - виды посредников - вопросы к ним 7. Заявка на кв (досье) - ваша история в письме - фото и прочее - заполнение формуляра 8. Страховки для договора 9. Виды кв в CH 10. Какая кв подходит вам **ВНИМАНИЕ! **Завтра состоится 3-я встреча, где будем повторять материал для новичков (30 мин). Оставшееся время (1,5 часа) посвятим разбору объяв и подаче заявок на их. Приходите с формулярами или с компьютерами или смартфонами. Будем писать письма и подавать заявки вместе. Вопросы? Пишите в комментах ниже или мне @VladiSwiss До завтра! Встреча по адресу: https://goo.gl/maps/tauZZE5XZgUJM7Hs7 * CH = Confoederatio Helvetica - это латинское название Швейцарской Конфедерации',\n",
       " '18. О жилье (как найти, особенности аренды)',\n",
       " 'Що таке втрата дому і як її пережити З початком повномасштабної війни поняття дому значно розширилося. Це і фізичний будинок, у якому зберігаються дорогі нам речі, і рідне місто, де ми виросли, і оточення близьких друзів, і незнайомі нам люди, які захищають країну в лавах ЗСУ. Багато українців втратили свій дім через повномасштабне вторгнення або виїхали з України, сумують за своїми квартирами та вимушені облаштовувати життя заново. За попередніми даними від заступниці директора департаменту житлової політики та благоустрою Міністерства розвитку громад і територій Світлани Старцевої, в Україні станом на 1 червня 3,5 млн українців мають пошкоджене або зруйноване житло. Крім житла, українці втрачають близьких людей, повсякденний ритм життя, спокій і базове відчуття безпеки. Спільно з ООН Жінки ми поговорили з психологинею SafeWomenHUB Тетяною Франчук про втрату звичного для нас середовища, як її пережити і як підтримувати тих, хто перебуває поруч, деталі: https://www.wonderzine.com.ua/wonderzine/life/life/11757-scho-take-vtrata-domu-i-yak-yiyi-perezhiti #StandwithUkraine',\n",
       " 'Иногда и местные ищут квартиру месяцами и даже годами имея стабильный рабочий котнтракт и получают десятками отказы.',\n",
       " '82 квартиры отказали?😬',\n",
       " 'Ну и чего вы переживаете? Может как раз вам подбирают более комфортное жилье.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[(df.cluster_names==\"Accomodation\")].nlargest(10, \"messageForwards\").messageText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Float64Index([27267.0, 17493.0, 13924.0, 13039.0, 11668.0, 11448.0, 11071.0,\\n              10563.0,  9478.0,  9384.0],\\n             dtype='float64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universität Zürich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[df\u001b[39m.\u001b[39;49mmessageForwards\u001b[39m.\u001b[39;49mnlargest(\u001b[39m10\u001b[39;49m)]\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/frame.py:3810\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3808\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3809\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3810\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3812\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/indexes/base.py:6111\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6109\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6111\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6113\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6115\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/pandas/core/indexes/base.py:6171\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6169\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6170\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 6171\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6173\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   6174\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Float64Index([27267.0, 17493.0, 13924.0, 13039.0, 11668.0, 11448.0, 11071.0,\\n              10563.0,  9478.0,  9384.0],\\n             dtype='float64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "df[df.messageForwards.nlargest(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model after merge topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BERTopic.load(\"../models/BERTopic100CharMin2500CharMax_10Classes/merge_topics/BERTopicmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probabilities = model.fit_transform(docs[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_representative_docs().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f\"../models/BERTopic100CharMin2500CharMax_10Classes/merge_topics/representative_docs.xlsx\", engine='xlsxwriter')\n",
    "for i in model.get_representative_docs().keys():\n",
    "    print(i)\n",
    "    df = pd.DataFrame(model.get_representative_docs()[i], columns=['message'])\n",
    "    df.to_excel(writer, sheet_name=model.get_topic_info()[model.get_topic_info()['Topic']==i]['Name'].values[0][:31])\n",
    "writer.save()\n",
    "model.get_topic_info().to_csv(f\"../models/BERTopic100CharMin2500CharMax_10Classes/merge_topics/topic_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=BERTopic.load(\"../models/BERTopic100CharMin2500CharMax_20Classes/BERTopicmodel\")\n",
    "with open('../data/BERTopicInput100CharMin2500CharMax.csv') as file:\n",
    "    lines = file.readlines()\n",
    "    docs = [line.rstrip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics2, probabilities2 = model2.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../models/BERTopic100CharMin2500CharMax_20Classes/probabilities.pkl\",'wb') as f:\n",
    "    pickle.dump(probabilities2, f)\n",
    "with open(\"../models/BERTopic100CharMin2500CharMax_20Classes/topics.pkl\",'wb') as f:\n",
    "    pickle.dump(topics2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/BERTopic100CharMin2500CharMax_20Classes/topics.pkl\",'rb') as f:\n",
    "    x = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 93.8M/1.12G [00:05<01:22, 12.3MB/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kiliansprenkamp/Desktop/OneDrive - Universität Zürich UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X61sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(img_folder, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X61sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39m'\u001b[39m\u001b[39mFlickr8k_Dataset.zip\u001b[39m\u001b[39m'\u001b[39m):   \u001b[39m#Download dataset if does not exist\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X61sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     util\u001b[39m.\u001b[39;49mhttp_get(\u001b[39m'\u001b[39;49m\u001b[39mhttps://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mFlickr8k_Dataset.zip\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X61sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     util\u001b[39m.\u001b[39mhttp_get(\u001b[39m'\u001b[39m\u001b[39mhttps://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFlickr8k_text.zip\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kiliansprenkamp/Desktop/OneDrive%20-%20Universit%C3%A4t%20Z%C3%BCrich%20UZH/migrantZurich/unsupervised-migrant-telegram-analysis/reports/BERTopic.ipynb#X61sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m folder, file \u001b[39min\u001b[39;00m [(img_folder, \u001b[39m'\u001b[39m\u001b[39mFlickr8k_Dataset.zip\u001b[39m\u001b[39m'\u001b[39m), (caps_folder, \u001b[39m'\u001b[39m\u001b[39mFlickr8k_text.zip\u001b[39m\u001b[39m'\u001b[39m)]:\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/sentence_transformers/util.py:285\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, path)\u001b[0m\n\u001b[1;32m    283\u001b[0m total \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(content_length) \u001b[39mif\u001b[39;00m content_length \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    284\u001b[0m progress \u001b[39m=\u001b[39m tqdm(unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m, total\u001b[39m=\u001b[39mtotal, unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 285\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m req\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[1;32m    286\u001b[0m     \u001b[39mif\u001b[39;00m chunk: \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    287\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/urllib3/response.py:627\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 627\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    629\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    630\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/urllib3/response.py:566\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    563\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    565\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 566\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/site-packages/urllib3/response.py:532\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    530\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    531\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/http/client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 463\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    464\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    465\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/http/client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    502\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    504\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    509\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/refugeeAnalysis/lib/python3.9/ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Flickr 8k images\n",
    "img_folder = 'photos/'\n",
    "caps_folder = 'captions/'\n",
    "if not os.path.exists(img_folder) or len(os.listdir(img_folder)) == 0:\n",
    "    os.makedirs(img_folder, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists('Flickr8k_Dataset.zip'):   #Download dataset if does not exist\n",
    "        util.http_get('https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip', 'Flickr8k_Dataset.zip')\n",
    "        util.http_get('https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip', 'Flickr8k_text.zip')\n",
    "\n",
    "    for folder, file in [(img_folder, 'Flickr8k_Dataset.zip'), (caps_folder, 'Flickr8k_text.zip')]:\n",
    "        with zipfile.ZipFile(file, 'r') as zf:\n",
    "            for member in tqdm(zf.infolist(), desc='Extracting'):\n",
    "                zf.extract(member, folder)\n",
    "images = list(glob.glob('photos/Flicker8k_Dataset/*.jpg'))\n",
    "\n",
    "# Prepare dataframe\n",
    "captions = pd.read_csv(\"captions/Flickr8k.lemma.token.txt\",sep='\\t',names=[\"img_id\",\"img_caption\"])\n",
    "captions.img_id = captions.apply(lambda row: \"photos/Flicker8k_Dataset/\" + row.img_id.split(\".jpg\")[0] + \".jpg\", 1)\n",
    "captions = captions.groupby([\"img_id\"])[\"img_caption\"].apply(','.join).reset_index()\n",
    "captions = pd.merge(captions, pd.Series(images, name=\"img_id\"), on=\"img_id\")\n",
    "\n",
    "# Extract images together with their documents/captions\n",
    "images = captions.img_id.to_list()\n",
    "docs = captions.img_caption.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"wuhu\")\n",
    "model = SentenceTransformer('clip-ViT-B-32')\n",
    "print(\"wuhu\")\n",
    "# Prepare images\n",
    "batch_size = 32\n",
    "print(\"wuhu\")\n",
    "nr_iterations = int(np.ceil(len(images) / batch_size))\n",
    "print(\"wuhu\")\n",
    "# Embed images per batch\n",
    "embeddings = []\n",
    "for i in tqdm(range(nr_iterations)):\n",
    "    start_index = i * batch_size\n",
    "    end_index = (i * batch_size) + batch_size\n",
    "\n",
    "    images_to_embed = [Image.open(filepath) for filepath in images[start_index:end_index]]\n",
    "    img_emb = model.encode(images_to_embed, show_progress_bar=False)\n",
    "    embeddings.extend(img_emb.tolist())\n",
    "\n",
    "    # Close images\n",
    "    for image in images_to_embed:\n",
    "        image.close()\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model)\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings[:123])\n",
    "captions[\"Topic\"] = topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('refugeeAnalysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38bb9b58d9ea7be5a20c75aa0b89a578c4bb72fb8d5231ed76f30ad5b765ca05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
